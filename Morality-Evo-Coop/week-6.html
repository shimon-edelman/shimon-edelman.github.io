<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Morality and the Evolution of Cooperation — week 6</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2021 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 6 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Morality and the Evolution of Cooperation</h1>
    <p><a href="http://kybele.psych.cornell.edu/~edelman">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 6: Evolution of conscience and the internalization of norms</h2>
  </div>
<!--  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%> -->

</div>
<!-- END COVER PAGE -->



<div  CLASS="slide">
  <h1>Week 6: evolution of conscience and the internalization of norms</h1>

  <P>
    <ul>
      <li>
	<I>Learning to be thoughtless: social norms and individual competition</I> [Epstein, 2001].
      </li>
    </ul>
  </P>
  <P>
    This work studies "a phenomenon that has been essentially ignored,
    namely that individual thought – or computing – is often inversely
    related to the strength of a social norm. Once a norm is
    entrenched, we conform thoughtlessly. In this model, agents learn
    how to behave (what norm to adopt), but – under a strategy I term
    Best Reply to Adaptive Sample Evidence – they also learn how much
    to think about how to behave. How much they are thinking affects
    how they behave, which – given how others behave – affects how
    much they think. In short, there is feedback between the social
    (interagent) and internal (intra-agent) dynamics. In addition, we
    generate the stylized facts regarding the spatio-temporal
    evolution of norms: local conformity, global diversity, and
    <a href="https://en.wikipedia.org/wiki/Punctuated_equilibrium"
    target=new>punctuated equilibria</a>." 
  </P>
	
</DIV>



<div  CLASS="slide">
  <h1>motivation</h1>

  <P>
    "When I’d had my coffee this morning and went upstairs to get
    dressed for work, I never considered being a nudist for the
    day. When I got in my car to drive to work, it never crossed my
    mind to drive on the left. And when I joined my colleagues at
    lunch, I did not consider eating my salad barehanded; without a
    thought, I used a fork."
  </P>
  <P>
    The point is that many social conventions have two features
    of interest:
    <ul>
      <li>
	First, they are self-enforcing behavioral
	regularities.
      </li>
      <li>
	But second, once entrenched, we conform without
	thinking about it.
      </li>
    </ul>
  </P>
  <P>
    Indeed, this is one reason why social norms are useful; they
    obviate the need for a lot of individual computing. After all, if
    we had to go out and sample people on the street to see if nudism
    or dress were the norm, and then had to sample other drivers to
    see if left or right were the norm, and so on, we would spent most
    of the day figuring out how to operate, and we would not get much
    accomplished.
  </P>
  <P>
    <a href="https://www.theholocaustexplained.org/resistance-responses-collaboration/non-conformity/"
    target=new>Thoughtless conformity</a>, while useful in such
    contexts, is frightening in others – as when norms of
    discrimination become entrenched. The literature on the evolution
    of norms and conventions has focused almost exclusively on the
    first feature of norms – that they are self-enforcing behavioral
    regularities.
  </P>
  
</DIV>



<div  CLASS="slide">
  <h1>an agent-based computational model</h1>

  <P>
    This model posits a ring of interacting agents. Each agent
    occupies a fixed position on the ring and has two attributes:
    <ol>
      <li>
	A binary ‘norm’ (as in ‘drive on the right (R) vs. drive on
	the left (L)’). Initially, agents are assigned norms.
      </li>
      <li>
	A sampling radius.
      </li>
    </ol>
  </P>
  <P>
    Agents update their norms based on observation of agents within
    their sampling radius, which is heterogeneous across agents.  It
    is updated, or ‘adapted’, incrementally according to a simple
    rule.
  </P>
  <P>
    <B>Radius Update Rule.</B>  Imagine being an agent with current
    sampling radius of \(r\).
    <ul>
      <li>
	First, survey all \(r\) agents to the left and all \(r\)
	agents to the right. Some have \(L\) as their norm and some
	have \(R\).
      </li>
      <li>
	Let \(F(r)\) be the relative frequency of \(R\)s at radius
	\(r\). Now, make the same computation for radius \(r + 1\).
      </li>
      <li>
	If \(F(r + 1) \neq F(r)\), then increase your search radius to
	\(r + 1\); otherwise, compute \(F(r-1)\).
      </li>
      <li>
	If \(F(r-1) = F(r)\), then reduce your search radius to
	\(r-1\).
      </li>
      <li>
	If neither condition obtains (i.e., if \(F(r +1) = F(r) \neq
	F(r −1))\), leave your search radius unchanged at \(r\).
      </li>
    </ul>
  </P>
  <P>
    <small>
      Agents are ‘lazy statisticians’. If they are getting a different
      result at a higher radius \((F(r+1) \neq F(r))\), they increase
      the radius (because larger-sample statistics are more
      reliable). But they are also lazy: if there’s no difference at
      the higher radius, they check a lower one.  If there is no
      difference between that and their current radius \((F(r-1) =
      F(r))\), they reduce the radius.
    </small>
  </P>
    
</DIV>


<div  CLASS="slide">
  <h1>norm update rule</h1>

  <P>
    The <B>Norm Update Rule</B> is extremely simple:
    <DIR><DIR> Match the majority within your radius.
    </DIR></DIR>
  </P>
  <P>
    If, at the updated radius, Ls outnumber Rs, then adopt the L
    norm. In summary, the rule is: <I>When in Rome, do as the
    (majority of) Romans do, with the (adaptive) radius determining
    the ‘city limits’.</I> 
  </P>
  <P>
    This rule is equivalent to <I>Best Reply to Sample Evidence</I> with a
    symmetric <a href="https://en.wikipedia.org/wiki/Normal-form_game"
    target=new>payoff matrix</a>:
    <div align=center>
    <table>
      <tr>
	<td></td><td align=center>L</td><td align=center>R</td>
      </tr>
      <tr>
	<td>L</td><td>(1,1)</td><td>(0,0)</td>
      </tr>
      <tr>
	<td>R</td><td>(0,0)</td><td>(1,1)</td>
      </tr>
    </table>
    </div>
  </P>
  <P>
    The rule maximizes the
    <a href="https://en.wikipedia.org/wiki/Expected_value"
    target=new>expected</a> <a href="https://en.wikipedia.org/wiki/Utility"
    target=new>utility</a> (sum of payoffs) in playing the agent’s
    sample population. The key point introduced here is that each
    individual’s sample size is itself adaptive. This is why the
    individual’s combined (norm and search radius) updating procedure
    can be called <I>Best Reply to Adaptive Sample Evidence.</I>
  </P>
  <P>
    Finally, there is generally some probability that an agent will
    adopt a random L or R ("noise").
  </P>

</DIV>


<div  CLASS="slide">
  <h1>the graphics</h1>

  <P>
    With this set-up, there are two things to keep track of: the
    evolution of social norm patterns on the agent ring, and the
    evolution of individual search radii.
  </P>
  <P>
    In the runs shown below, there are 191 agents. They are drawn at
    random and updated asynchronously.  Clearly, each agent’s
    probability of being drawn k times per cycle (191 draws with
    replacement) has the
    <a href="https://en.wikipedia.org/wiki/Binomial_distribution"
    target=new>Binomial distribution</a> \(b(k; n, 1/n)\), with \(n =
    191\).  Agents who are not drawn keep their previous norm. After
    191 draws – one cycle – the new ring is redrawn below the old one
    (as a horizontal series of small contiguous black and white dots),
    so time is progressing down the page.
  </P>
  <P>
    There are two Panels. The left Panel shows the evolution of norms,
    with L-agents colored black and R-agents colored white. With the
    exception of Run 4, each entire Panel displays 300 cycles (each
    cycle, again, being a sequence of 191 random calls.)  The right
    window shows the evolution of search radii, using
    grayscale. Agents are colored black if \(r = 1\), with
    progressively higher radii depicted as progressively lighter
    shades of gray.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>monolithic social norm, individual computing dies out</h1>

  <img src="Epstein01-fig1.png" class="figure-right" height=450>
  <P>
    For this first run, we set all agents to the L norm (coloring them
    black) initially and set noise to zero. Each agent has a random
    initial search radius between 1 and 60 (artificially high to show
    the strength of the result in the monolithic case).
  </P>
  <P>
    <I>Right panel.</I> The uppermost line (the initial population
    state) (191 agents across) is multi-shaded, reflecting the random
    initial radii. Let us now apply the radial update rule to an
    arbitrary agent with radius r.  First look out further. We find
    that \(F(r + 1) = F(r)\), because all agents are in the L norm
    (black). Now, try a smaller radius. Because \(F(r−1) = F(r)\), the
    agent reduces from \(r\) to \(r - 1\).
  </P>
  <P>
    <I>Left panel.</I> Now, apply the norm update rule. At this new
    radius, match the majority. Clearly, this is L (black), so stay
    L. This is the same logic for all agents. Thus, the social norm
    remains entrenched, and, as shown in the right panel, individual
    ‘thinking’ dies out – radii all shrink to the minimum of 1
    (colored black).
  </P>

</DIV>


<div  CLASS="slide">
  <h1>random initial norms, individual computing at norm boundaries</h1>

  <img src="Epstein01-fig2.png" class="figure-right" height=450>
  <P>
    With noise still at zero, we now alter the initial conditions
    slightly. In this, and all subsequent runs, the initial maximum
    search radius is 10. Rather than set all agents in the L norm
    initially, we give them random norms. The typical result is shown
    here. 
  </P>
  <P>
    <I>Left panel.</I> There is rapid lock-in to a global pattern of
    alternating local norms on the ring.
  </P>
  <P>
    <I>Right panel.</I> Deep in each local norm, agents are colored
    black: there is no individual computing (no ‘thinking’). In
    contrast, agents at the boundary of two norms must worry about how
    to behave, and so are bright-shaded.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>complacency in new norms</h1>

  <img src="Epstein01-fig3.png" class="figure-right" height=450>
  <P>
    In the 1960’s, people smoked in airplanes, restaurants, and
    workplaces, and no one gave it much thought. Today, it is equally
    entrenched that smoking is prohibited in these circumstances.
    After the ‘revolution’ entirely new norms prevail, but once
    entrenched, people become inured to them; they are observed every
    bit as thoughtlessly (in our sense) as before.
  </P>
  <P>
    This run begins as before, with randomly distributed initial norms
    and zero noise. The system reaches equilibrium, locking into
    neighborhood norms (as before, these appear as vertical stripes
    over time). Then, at t = 130, we shock the system, boosting the
    level of noise to 1.0, and holding it there for ten periods. Then
    we turn the noise off and watch the system re-equilibrate.
  </P>
  <P>
    After the shock, an entirely new pattern of norms is evident on
    the left. But, looking at the right (radius) panel, we see that
    many agents who were thoughtlessly in the L norm (black) before
    the shock are equally thoughtlessly in the R norm (white) after.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>time series plot</h1>

  <img src="Epstein01-fig4.png" class="figure-right" height=450>
  <P>
    A time series plot of average radius over the course of this
    experiment is also revealing. Following an initial transient
    phase, the mean radius attains a steady state value of roughly
    2.25. During the brief ‘shock’ period of maximum noise, the
    average radius rises sharply, reflecting the agents’ search for
    appropriate behavior in a period of social turmoil.
  </P>
  <P>
    One might expect that, with noise restored to zero, the average
    radius would relax back to its pre-shock value.  In fact, the
    post-shock steady state depends on the postshock number of local
    norms. The lower the diversity, the lower the number of borders
    and, as in the present run, the lower the average radius.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>noise of 0.15 and endogenous neighborhood norms</h1>

  <img src="Epstein01-fig5.png" class="figure-right" height=450>
  <P>
    Now, noise levels of zero and one are not especially plausible.
    The next four runs use the same initial conditions as Run 2, but
    add increasing levels of noise.  With noise set at 0.15, we obtain
    dynamics of the sort shown here.  Again, we see that individual
    computing is most intense at the norm borders – regions outlining
    the norms. We also see the emergence and disappearance of norms,
    the most prominent of which is the white island that comes into
    being and then disappears. One can think of islands as indicating
    punctuated equilibria.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>time series for noise of 0.15</h1>

  <img src="Epstein01-fig6.png" class="figure-right" height=450>
  <P>
    Following an initial transient phase, the average search radius
    clearly settles at roughly 2.0 for this realization.5 Even at zero
    cost of sampling, in other words, a ‘stopping rule’ for the
    individual search radius emerges endogenously through local agent
    interactions. And this obtains at all levels of noise.
  </P>

</DIV>


<div  CLASS="slide">
  <h1>maximum noise</h1>

  <img src="Epstein01-fig11.png" class="figure-right" height=350>
  <P>
    Finally, we fix the noise level at its maximum value of 1.0,
    meaning that agents are adopting the Left and Right convention
    totally at random. One might assume that, in this world of maximum
    randomness, agents would continue to expand their search to its
    theoretical maximum of \((n - 1)/2\), or 95 in this case. But this
    is not what happens.
  </P>
  <img src="Epstein01-fig12.png" class="figure-right" height=300>
    <P>
      Indeed, as the time series plot shows, it rises only to about
      4.5 (the 95% confidence interval is [4.53, 4.63]).  Thinking –
      individual computing – is minimized in the monolithic world of
      Run 1.  But, it does not attain its theoretical maximum in the
      totally random world of this run.
    </P>
    <HR>
    <P>
      Bottom line:
      <blockquote>
	Individual computing is often inversely related to the strength of a social
	norm. As norms become entrenched, we conform thoughtlessly.
      </blockquote>
    </P>

</DIV>



    <div  CLASS="slide">
  <h1>the emergence of conscience</h1>

  <P>
    <ul>
      <li>
	<I>How selfish genes beget selfless beings: the evolution of
	  conscience</I> [Smirnova and Odouard, 2020].
      </li>
    </ul>
  </P>
  <P>
    The Python/Mesa code for this project is available
    <a href="Evolution-Of-Conscience-master.zip" target=zip>HERE</a>
    (courtesy of Diana Smirnova and Victor Odouard).
  </P>
  <P>
    Because our <a href="https://en.wikipedia.org/wiki/Conscience"
    target=new>consciences</a> urge cooperation even towards those who
    are not our kin (<I>inclusivity</I>), and even when no one is
    watching (<I>sincerity</I>), it eludes many of the previously
    given explanations for the evolution of cooperation, such as
    reciprocity, kin selection, and even punishment (which can only
    occur when behaviors are observed). While group-level selection is
    a candidate cause, in previous studies of agent-based models has
    demonstrated a limited capacity to evolve cooperation in large
    groups.
  </P>
  <P>
    In our model, conscience is, for the first time, represented by
    more than a simple “always cooperate” strategy, as it is affected
    by the behaviors of other individuals in society. We believe this
    is what allows conscience to grow and thrive, even in large
    societies. Thus, we propose the group-level evolution of
    conscience as a major catalyst for cooperation in large (>1000
    people) human societies.
  </P>
  
</DIV>



<div  CLASS="slide">
  <h1>the problem of truly selfless morals</h1>

  <P>
    Ever since Darwin himself pointed it out, it has been known that
    a trait that predisposes its carrier to altriusm is not
    evolutionarily stable.
  </P>
  <P>
    The persistence of predisposition to truly selfless behavior (as
    opposed to mere
    <a href="https://en.wikipedia.org/wiki/Tit_for_tat#Game_theory"
    target=new>tit-for-tat</a>) is particularly difficult to explain.
    Conscience, and its constituent moral emotions such as guilt and
    shame, is a powerful force that promotes moral behavior. However,
    there are two characteristics of conscience that make it difficult
    to explain evolutionarily:
    <ul>
      <li>
	<I>Sincerity</I>. Conscience remains in force even when no one
	is looking.
      </li>
      <li>
	<I>Inclusivity</I>. Conscience prods us into altruism towards
	all members of our community – not just our kin.
      </li>
    </ul>
  </P>
  <P>
    Note that sincerity precludes a purely reciprocal explanation for
    conscience, since reciprocity only works when others are aware of
    your actions. Inclusivity, on the other hand, clearly precludes a
    kin-based explanation for conscience.
  </P>
  <P>
    How could sincere and inclusive conscience have evolved? Here, we
    explore whether multi-level selection could have done it, using an
    agent-based model to simulate both the intra- and inter-group
    evolutionary dynamics of societies. Specifically, we explore the
    hypothesis that conscience can act as an internal enforcer of
    cooperation. This in turn makes some societies as an aggregate
    more fit, allowing them to outcompete other societies (as Darwin
    originally proposed).
  </P>
   
</DIV>    
    


<div  CLASS="slide">
  <h1>the main characteristics of our model</h1>

  <P>
    <ol>
      <li>
	<I>Cooperation/Defection choice</I>: at each time step, each
	agent has a choice of whether to cooperate or defect. These
	choices are abstract, but they can be thought of as
	corresponding to concrete behaviors, such as helping on a
	group hunt, or stealing from the group.
      </li>
      <li>
	<I>Reward scheme</I>: agents who cooperate must pay an
	individual cost to cooperate, but they also produce a public
	benefit greater than the cost they incur. Defectors simply
	free-ride off the public benefit.
      </li>
      <li>
	<I>Individual selection</I>: low-fitness individuals die off,
	while high-fitness individuals survive and pass on their
	strategy to offspring.
      </li>
      <li>
	<I>Inter-group selection</I>: groups compete with each other,
	either through direct conflict or indirect competition for
	resources.
      </li>
    </ol>
  </P>
  <P>
    Notice that individual selection and inter-group selection are in
    conflict. Conscience-equipped individuals <B>under-perform, but
    conscience equipped groups over-perform</B>. Thus, the only way
    for conscience to win out is for the group advantage afforded by
    conscience to outweigh the individual costs.
  </P>
  
</DIV>



<div  CLASS="slide">
  <h1>clarification of terms</h1>

  <P>
    There are differences between altruistic, cooperative, and
    moral behaviors.  We suggest that they form nested sets:
    $$ \text{altruistic behaviors} \subset \text{cooperative behaviors}
    \subseteq \text{moral behaviors} $$
  </P>
  <P>
    The inclusion of (and perhaps the identity between) the set of
    cooperative behaviors and the set of moral behaviors is supported
    by the study of morality in 60 societies by Curry et al. (2019)
    [<a href="unit-16.html" target=new>unit 16</a>].
    As for altruism, only a subset of cooperative acts are considered
    altruistic – cooperative acts made voluntarily, in the absence of
    any quid pro quo external rewards. Thus, every altruistic act is
    cooperative, but not every cooperative act is altruistic (for
    instance, reciprocity is cooperative, but not altruistic).
  </P>
  <img src="Smirnova20-tab4.png" class="figure-right" height=300>
  <P>
    We define <B>conscience</B> as a combination of
    <ol>
      <li>
	the capacity to absorb moral norms, and
      </li>
      <li>
	internal enforcement of those norms.
      </li>
    </ol>
  </P>
  <P>
    Enforcement is mediated by emotions such as guilt and
    shame. Because it is internal, the acquisition of conscience can
    be thought of as the internalization of community standards.
  </P>

</DIV>

    

<div  CLASS="slide">
  <h1>to cooperate or not?</h1>

  <P>
    Because we use cooperation as a proxy for morality, we can build
    on past research into the evolutionary stability of cooperation in
    groups.
  </P>
  <table>
    <tr>
      <th>
	mutualistic cooperation
      </th>
      <th>
	Prisoner’s Dilemma 
      </th>
    </tr>
    <tr>
      <td style="text-align:center">
	<img src="Smirnova20-tab1.png" height=200>
      </td>
      <td style="text-align:center">
	<img src="Smirnova20-tab2.png" height=200>
      </td>
    </tr>
    <tr>
      <td>
	In the simple situation described by this payoff matrix,
	cooperation is the dominant strategy: it benefits both
	parties, and there is no opportunity for a free-rider to
	refrain from cooperating and still gain benefit. Example:
	ox-peckers eat pests of rhinoceroses and zebras, providing the
	ox-pecker with food and the zebra with pest control.
      </td>
      <td>
	In a
	<a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma"
	target=new>Prisoner’s Dilemma</a> situation, a cooperating
	agent produces a benefit of 2 for the other player, but must
	pay an individual cost of 1. While the aggregate benefit is
	highest if both agents choose to cooperate, the dominant
	strategy for both agents is to defect, and “free-ride” off the
	good that the other agent produced.
      </td>
    </tr>
  </table>

      <P>
	In our model, agents face a choice between cooperation and
	defection similar to the iterated version of the
	<a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma"
	target=new>Prisoner’s Dilemma</a>. 
      </P>
   
</DIV>    
    


    
<div  CLASS="slide">
  <h1>the model</h1>

  <img src="Smirnova20-tab3.png" class="figure-right" height=250>
  <P>
    In a series of rounds, agents choose whether to cooperate or
    defect. In any given round, each agent has a certain probability
    of having its actions observed. Each agent is aware of its
    probability of being caught and can make decisions based on
    this.
  </P>
  <P>
    This allows us to distinguish between sincere and insincere
    strategies. <B>Agents who cooperate even when they have a low
    probability of being observed can be said to have conscience — an
    internal enforcer.</B>
  </P>
  <P>
    Agent strategies are driven by the payoff matrix. In each round,
    every agent gets a base increase \(f\) in fitness. The agents can
    also choose to cooperate, in which case they incur a cost \(c\),
    but produce a benefit \(b > c\), since cooperation should produce
    a benefit greater in sum than the costs incurred by the individual
    agents (why else would cooperation be beneficial?). Agents who are
    observed to have defected do not receive any of the collective
    benefit, while everyone else gets an equal share, represented by
    \(\bar{b}\). Therefore, this model contains an element of
    punishment, but only for observed defectors. This leaves room for
    conniving agents to cooperate only when they are likely to be
    observed (the antithesis of conscience).
  </P>
   
</DIV>    
    
  

  
<div  CLASS="slide">
  <h1>the four types of agents</h1>

  <P>
    Each agent is characterized by one of four strategies, which guide
    their decision on whether to cooperate or defect. Their strategy
    corresponds to the “default choice,” which they will follow with
    probability \(1−\epsilon\); with probability probability
    \(\epsilon\) they deviate from their default choice.
    <ol>
      <li>
	<I>Miscreants</I> defect by default.
      </li>
      <li>
	<I>Deceivers</I> essentially act as reward-maximizers, by
	predicting cooperation and defection payoffs. These are
	estimated from the benefits of cooperation from the previous
	round and their probability of being observed in the current
	round. Expected payoff from cooperating is calculated as \(f_c
	= f − c + \bar{b}_{t−1}\) and the expected payoff from
	defecting as \(f_d = f + (1 − p_{obs}) \bar{b}_{t−1}\). When
	\(f_c \geq f_d\), they cooperate by default; otherwise, they
	defect by default.
      </li>
      <li>
	<I>Citizens</I> act based on how many agents cooperated in the
	previous round. When the proportion of other agents that
	cooperated reached a threshold \(T\), they cooperate by
	default; otherwise, they act as reward-maximizers.
      </li>
      <li>
	<I>Saints</I> cooperate by default.
      </li>
    </ol>
  </P>
  <P>
    Note that deceivers may act cooperatively at times, but never
    altruistically: their cooperation is always
    self-interested. Citizens, on the other hand, can be said to have
    a conscience, because their morality (the choice to cooperate)
    does not depend on whether or not they are being watched.  That
    said, citizens only feel pressure from their conscience <I>if
    other agents are cooperating</I>. Thus, conscience is often
    conditioned on the feeling that those around you are doing their
    part, but importantly, not on the likelihood of getting caught.
  </P>
  
</DIV>    
    


<div  CLASS="slide">
  <h1>multilevel selection</h1>

  <P>
    The agents of various types compete with each other through a
    mechanism of survival and reproduction: agents with lower fitness
    are more likely to die, and agents with higher fitness are more
    likely to reproduce (and pass their strategy on to their
    offspring). This occurs in such a way as to keep group sizes
    constant.
  </P>
  <P>
    This individual selection process will clearly favor the
    reward-maximizers. To incorporate MULTI-LEVEL SELECTION, we also
    include a mechanism by which groups are randomly paired, and, with
    some probability, engage in conflict. The likelihood of victory
    for group \(i\) in a conflict with group \(j\) is

    $$
    \frac{1}{2} \left(1 + \frac{F_i − F_j}{F_i + F_j}\right)
    $$
    
    where \(F_i\) is the aggregate fitness of group \(i\). The higher
    group \(i\)’s aggregate fitness is in comparison to group \(j\),
    the more likely group \(i\) is to be victorious.
  </P>
  <P>
    The level of cooperation within a group is directly proportional
    to aggregate fitness of its members, so groups with higher levels
    of cooperation have a higher average fitness than groups with
    lower levels of cooperation or no cooperation at all. Thus,
    cooperative groups have an advantage in conflicts against other
    groups.
  </P>
  <P>
    Now, <B>if the citizens manage to outcompete the deceivers, it
    would be a momentous achievement</B>.  After all, deceivers are
    reward-maximizers. The dominance of citizens, then, would signify
    (at least the start of) a transfer of evolutionary focus from the
    individual to the group.
  </P>
  
</DIV>


 
  
<div  CLASS="slide">
  <h1>effects of benefit-to-cost ratio and base fitness</h1>

  <img src="Smirnova20-fig1.png" class="figure-right" height=400>
  <P>
    <B>We found that group-level selection was sufficient to bring
    about the evolution of conscience, when the ratio of the public
    benefit to individual cost was high enough.</B> This result
    persisted even as group sizes became large, of over one thousand
    members.
  </P>
  <P>
    Almost all simulations we ran ended with either complete dominance
    of the miscreant-deceiver population, or complete dominance of the
    citizen-saint population. <small> Once these equilibria were
    reached, the two surviving agent types would either always defect
    (in the former case) or always cooperate (in the latter case) so
    they became essentially evolutionarily indistinguishable and one
    type did not go on to dominate the other. However,
    pre-stabilization, citizens tended to outperform saints, since
    they are harder to take advantage of, and thus usually saints were
    less numerous in final equilibria.  An analogous observation holds
    for deceivers and miscreants: pre-stabilization, deceivers tended
    to perform better than miscreants, since they could cooperate if
    it would likely be personally advantageous (for instance, if they
    were very likely to get caught in defection). However, once
    matters stabilized to an all-defection scenario, getting caught
    was immaterial since the punishment in our model was deprivation
    from the group benefit – but when everyone is defecting, there is no
    group benefit to be deprived of.</small>
  </P>
  <P>
    By far the most important factor in determining whether conscience
    could evolve was the ratio of group benefit to individual
    cost. Almost all simulations we ran with the 3.25 ratio converged
    to all-defection scenarios, while the simulations with the 3.75
    almost always converged to all-cooperation scenarios. Thus there
    is a clear tipping point here – only a small change in this ratio
    leads us from one extreme to another. Base fitness was also a very
    influential factor, especially at the frontier.
  </P>

  
</DIV>    
    


  
<div  CLASS="slide">
  <h1>effect of migration rate</h1>

  <img src="Smirnova20-fig2.png" class="figure-right" height=250>
  <P>
    We had expected that <B>migration</B> would have a negative effect on the
    evolution of conscience. This is because conscience, under our
    hypothesis, requires us to treat the group, rather than the
    individual, as the ultimate unit of selection. But if there is a
    high level of migration between groups, the unit cohesion of the
    group is compromised.
  </P>
  <P>
    The findings, however, were not so simple.  First, the migration
    rate was certainly a secondary factor to the benefit-to-cost
    ratio. We experimented with the migration rate at the
    frontier–that is, with a benefit-to-cost ratio equal to 3.5, and
    we observed a U-shaped pattern in its impact.
    <small>
    <ol>
      <li>
	With a migration rate of 0, all runs stabilized to
	citizen-saint dominance.
      </li>
      <li>
	With a migration rate of 0.1, deceiver-miscreant dominance
	occurred in a minority of runs: 13 runs ended with virtual
	citizen saint dominance (fewer than 3% defectors, usually 0),
	6 runs ended with absolute deceiver-miscreant dominance, and 1
	was somewhat ambiguous with mostly citizen-saint dominance,
	but 1000 straggling deceivers.
      </li>
      <li>
	With a migration rate of 0.2, the results were similar to 0.1:
	13 runs ended with citizen-saint dominance, and 7 with
	deceiver-miscreant dominance. Interestingly, here all
	dominance was absolute: each run ended with 100%
	miscreant-deceiver, or 100% saint-citizen.
      </li>
      <li>
	With a migration rate of 0.3, 18 runs ended with citizen-saint
	dominance and 2 with deceivermiscreant dominance. Again,
	dominance of either type of agent was absolute.
      </li>
      <li>
	With a migration rate of 0.4, or 0.5, all runs ended with
	citizen-saint dominance.
      </li>
    </ol>
    </small>
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>effect of conflict rate</h1>

  <img src="Smirnova20-fig3.png" class="figure-right" height=250>
  <P>
    <B>Group conflict</B>, on the other hand, had more predictable
    results. For a rate of 0 (no conflict), citizen-saints only
    dominated in 4 out of 20 runs. Then with a rate of 0.1, they
    dominated in 12 runs, peaking at a rate of 0.3 with citizen-saint
    dominance in 19 out of 20 runs. This, of course, is what we
    expect: in this model, conflict is the driver of group-level
    selection.
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>starting at a disadvantage</h1>

  <P>
    Most of our runs started out with equal numbers of miscreants,
    deceivers, saints, and citizens. To find out whether or not a
    small population of citizens or saints can “take over” if they
    start off as a minority (which they are likely to be when they
    first evolve), we tried starting with an initial distribution
    dominated by deceivers and miscreants.
  </P>
  <P>
    In these runs, only 2% of the agent population started off as
    citizens or saints.  At our frontier, with a benefit-to-cost equal
    to 3.5, conscience was never able to make it out–all runs ended
    with a deceiver-miscreant dominance. In fact, <B>a benefit to cost
    ratio of 7, double that of our usual frontier, was required for
    conscience to come up from behind. With this value, 17 out of 20
    runs in citizen-saint dominance.</B>
  </P>
  <P>
    We also tried another scenario, in which there was a single group
    completely dominated by citizens and saints. Could this group, due
    to its greater efficiency, outcompete the others and thus multiply
    across the map? Perhaps surprisingly, the answer was no, at least
    with the migration rate we had been using. We had to reduce
    migration to 1/10 of the initial parameter value (from 0.1 to
    0.01) before certain runs ended with citizen-saint-dominance. With
    a migration rate of 0.01, 12 of 20 runs ended in citizen-saint
    dominance, whereas with a rate of 0.1, all runs ended with
    deceiver-miscreant dominance.
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>discussion: level transitions</h1>

  <P>
    One way to think about this research is that it studies the
    question, at what point does the dominance of one level of natural
    selection (the social group) surpass the level below it?
  </P>
  <P>
    <B>Our major finding is that the primary quantity of interest is
    the ratio of group benefit to individual cost.</B> Specifically,
    the benefit-to-cost ratio seems to have some threshold, which
    might depend on certain parameters such as migration, after which
    the individual loses priority to the group.
  </P>
  <P>
    Interestingly, this threshold seems to be robust to changes in
    group size. In our case, this threshold was about
    3.5. Furthermore, reaching this threshold leads to a sudden tip
    from one extreme to the other. There is no stability in the middle
    ground.
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>the initial bump</h1>

  <P>
    The "threshold" benefit-to-cost ratio of 3.5 is quite high. A
    species that knows how to cooperate this well must have gradually
    worked up to this high efficiency-of-cooperation. How could this
    have happened?
  </P>
  <P>
    It is something like a CHICKEN-AND-EGG SITUATION. Conscience
    encourages cooperation. But in order for conscience to evolve, the
    benefits of cooperation must be extremely high. Thus, there needs
    to be an initial, non-conscience, catalyst of cooperation, that
    allows the species to “practice” cooperating.  Through this
    practice, a species can gradually increase the benefit-to-cost
    ratio of cooperation.
  </P>
  <P>
    This seems to be the role that self-interested cooperation
    mechanisms, such as mutualistic cooperation, reciprocity, and kin
    altruism, played in the beginning. These, after all, were the
    first types of cooperation to evolve–they exist widely throughout
    the animal kingdom, contrary to conscience. It is plausible that
    they provided that initial bump, in a sense, that allowed
    cooperation to pull itself up by its bootstraps in the human
    population. Then, once the conscience threshold was met, the
    conditions for conscience to mushroom throughout the population
    became ripe. Thus, initial cooperation sets off a positive
    feedback loop, by allowing conscience to evolve, which
    subsequently sparks even greater cooperation.
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>emergence and stability</h1>

  <img src="week-6.html" class="figure-right" height=250>
  <P>
    <B>Is a conscience-dominated equilibrium, in which all groups
    exhibit dominance of citizens and saints, stable?  From our
    experimental results, the answer seems to be a tentative yes.</B>
    Whenever, in our simulations, the number of miscreant-deceivers
    dipped below a certain level, they would invariably go all the way
    down to zero.
  </P>
  <P>The dynamics of this are probably quite interesting an deserve to
    be explored, because one might expect that an intelligent
    free-rider might be able to do quite well in a society where
    everyone is dutifully producing a public good. Here we hypothesize
    that any group that succumbs to an invasion of deceivers would
    quickly get quashed by another group that has achieved full
    cooperation.
  </P>
  <P>
    We found that <B>a minority of groups that have come to be
    dominated by conscience-possessing individuals can go on to
    outcompete groups of more selfish individuals, eventually
    replacing them. However, this only occurs when migration rates are
    very low.</B> When migration rates are too high,
    deceiver-miscreant populations begin to infiltrate the small
    number of conscience groups and “destroy them from within” by
    free-riding off of the altruistic individuals in those
    groups. Thus, the conditions for the initial emergence of
    conscience and the initial spread of conscience are both
    relatively delicate.
  </P>
   
</DIV>    
    


  
<div  CLASS="slide">
  <h1>summary</h1>

  <P>
    We examined a simple group selection mechanism for the evolution
    of conscience and found that even with large group sizes (> 1000)
    conscience – and thus cooperation — was able to flourish.
  </P>
  <P>
    Earlir work on the evolution of conscience found that group
    selection failed to produce cooperation in large societies [Boyd
    et al., 2003]. How was our simulation different?
    <ol>
      <li>
	 It contained more sophisticated cooperation strategies, which
	 as it turns out, more accurately mirror how our conscience
	 actually works. Many simulations in the past consisted simply
	 of a mix of unsophisticated cooperators and defectors. <B>In
	 our model, we included the <I>citizen</I> strategy:
	 “cooperate as long as others are cooperating”. Its inclusion
	 was essential to the survival of conscience-possessing
	 individuals — saints alone would not have made it.</B>
      </li>
      <li>
	Our model included punishment: defectors who were caught were
	punished for the transgression by being deprived of the group
	benefit.
      </li>
    </ol>
  </P>
  <P>
    Of course, conscience did not evolve under all circumstances. By
    far the most important factor was the benefit-to-cost ratio of
    cooperation. In fact, factors that we might have believed would
    play extremely important roles either had much less pronounced
    effects, or produced effects in unexpected ways. Migration had a
    U-shaped impact on the evolution of conscience, and group size
    barely played a role at all.
  </P>

</DIV>



<div  CLASS="slide">
  <h1>some open questions</h1>

  <P>
    <ul>
      <li>
	Why does group size play such a small role in level-changes?
	Answering this would probably requiring knowing the particular
	dynamics of a high benefit-to-cost ratio system that make it
	so conducive to a level-switch, even when group sizes are
	big.
      </li>
      <li>
	What if observation probability decreased as society size
	increased?
      </li>
      <li>
	Could conscience have evolved even in the absence of the
	punishment mechanism that we had in place?
      </li>
    </ul>
  </P>
   
</DIV>    

    
<div class="footer">
<p>Last modified: Fri Mar 12 2021 at 11:21:28 EST</p>
</div>
</body>
</html>
