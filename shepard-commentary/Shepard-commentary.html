<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 99.2beta8 (1.43)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Neural spaces: a general framework for the understanding of
cognition? A commentary on the article by R.&nbsp;N.&nbsp;Shepard</TITLE>
<META NAME="description" CONTENT="Neural spaces: a general framework for the understanding of
cognition? A commentary on the article by R.&nbsp;N.&nbsp;Shepard">
<META NAME="keywords" CONTENT="Shepard-commentary">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v99.2beta8">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="Shepard-commentary.css">

</HEAD>

<BODY >

<P>

<P>

<P>
<H1 ALIGN="CENTER">Neural spaces: a general framework for the understanding of
  cognition? </H1>
<H3 ALIGN="CENTER">A commentary on the article by R.&nbsp;N.&nbsp;Shepard</H3>
<P ALIGN="CENTER"><STRONG>Shimon Edelman 
<BR>  232 Uris Hall, Department of Psychology 
<BR>  Cornell University 
<BR>  Ithaca, NY 14853-7601, USA 
<BR>  <I>se37@cornell.edu</I> 
<BR>  <A NAME="tex2html1"
  HREF="http://kybele.psych.cornell.edu/~edelman">http://kybele.psych.cornell.edu/~edelman</A>
</STRONG></P>
<P ALIGN="CENTER"><STRONG> December 2000 </STRONG></P>

<P>

<H3>Abstract:</H3>
<DIV>

<P><I>
A view is put forward, according to which various aspects of the
structure of the world as internalized by the brain take the form of
``neural spaces,'' a concrete counterpart for Shepard's ``abstract''
ones. Neural spaces may help us understand better both the
representational substrate of cognition and the processes that operate
on it.
</i>
<P>
</DIV>
<P>

<P>
Shepard's meta-theory of representation, illustrated in the target
article on three examples (object motion, color constancy, and
stimulus generalization), can be given the following general
formulation: the existence of an invariant law of representation in a
given domain is predicated on the possibility of finding an ``abstract
space'' appropriate for its formulation. The generality of this
meta-theory stems from the observation that any sufficiently
well-understood physical domain will have a quantitative description
space associated with it. In the account of perceived motion, this is
the constraint manifold in what is called in mechanics (and robotics)
the configuration space. In color vision, it is the low-dimensional
linear space that can be related through principal component analysis
to the characteristics of natural illumination and surface
reflectances. In stimulus learning and generalization, it is the
``probabilistic landscape'' with respect to which Marr (1970)
formulated his Fundamental Hypothesis<A NAME="tex2html2"
  HREF="Shepard-commentary.html#foot38"><SUP>1</SUP></A> and over
which Shepard's (1987) ``consequential regions'' are defined.

<P>
A central thesis of the target article is that evolutionary pressure
can cause certain physical characteristics of the world to become
internalized by the representational system.  I propose that the
internalized structure takes the form of <EM>neural spaces</EM>, whose
topology and, to some extent, metrics, reflect the layout of the
represented ``abstract spaces.''<A NAME="tex2html3"
  HREF="Shepard-commentary.html#foot39"><SUP>2</SUP></A>
<P>
The utility of geometric formalisms in theorizing about neural
representation stems from the straightforward interpretation of
patterns of activities defined over ensembles of neurons as points in
a multidimensional space
[<A
 HREF="Shepard-commentary.html#Gallistel90">Gallistel, 1990</A>, <A
 HREF="Shepard-commentary.html#ChurchlandSejnowski92">Churchland and
 Sejnowski, 1992</A>, <A
 HREF="Shepard-commentary.html#Mumford94">Mumford, 1994</A>].  Four of the
issues stemming from the neural space (NS) approach to representation
that I raise here are: (1) its viability in the light of experimental
data, (2) the explanatory benefits, if any, that it confers on a
theory of the brain that adopts it, (3) the operational conclusions
from the adoption of the NS theoretical stance, and (4) the main
theoretical and experimental challenges it faces.

<P>

<H4><A NAME="SECTION00000010000000000000">
Viability.</A>
</H4>
The relatively few psychophysical studies designed specifically to
investigate the plausibility of attributing geometric structure to
neural representation spaces did yield supporting evidence. For
example, the parametric structure built into a set of visual stimuli
can be retrieved (using multidimensional scaling) from the perceived
similarity relationships among them
[<A
 HREF="Shepard-commentary.html#ShepardCermak73">Shepard and Cermak,
 1973</A>, <A
 HREF="Shepard-commentary.html#CorteseDyre96">Cortese and Dyre, 1996</A>, <A
 HREF="Shepard-commentary.html#CutzuEdelman96pnas">Cutzu and Edelman, 1996</A>].
Psychophysical evidence by itself cannot, however, be brought to bear
on the neurobiological reality of a neural space. To determine whether
or not the geometry of a postulated neural space is causally linked to
behavior, one needs to examine the neural activities directly.
Unfortunately, neurophysiological equivalents of the psychophysical
data just mentioned are very scarce. The best known direct functional
interpretation of neuronal ensemble response was given in connection
with mental rotation in motor control [<A
 HREF="Shepard-commentary.html#GeorgopoulosEtAl88">Georgopoulos et&nbsp;al., 1988</A>]. More
recently, an fMRI study of visual object representation that used
multidimensional scaling to visualize the layout of the voxel
activation space yielded a low-dimensional map that could be
interpreted in terms of similarities among the stimuli
[<A
 HREF="Shepard-commentary.html#EdelmanEtAl98fmri">Edelman et&nbsp;al., 1999</A>].

<P>

<H4><A NAME="SECTION00000020000000000000">
Potential benefits.</A>
</H4>
The representation space metaphor has been invoked as an explanatory
device in many different areas of cognition, from visual
categorization [<A
 HREF="Shepard-commentary.html#Edelman99book">Edelman, 1999</A>] to semantics
[<A
 HREF="Shepard-commentary.html#LandauerDumais97">Landauer and Dumais, 1997</A>].  In vision, this move has been used,
traditionally, to ground similarity and generalization. When a
transduction mechanism connecting the neural space to the external
world is specified, the geometric metaphor also provides a framework
for the treatment of veridicality of representations
[<A
 HREF="Shepard-commentary.html#Edelman99book">Edelman, 1999</A>], in a manner compatible with Shepard's idea of
second-order isomorphism between representations and their referents
[<A
 HREF="Shepard-commentary.html#ShepardChipman70">Shepard and Chipman, 1970</A>].  Conceptual spaces seem to offer a promising
unified framework for the understanding of other aspects of cognition
as well [<A
 HREF="Shepard-commentary.html#Gardenfors00">G&#228;rdenfors, 2000</A>].

<P>

<H4><A NAME="SECTION00000030000000000000">
Operational conclusions.</A>
</H4>
Adopting the NS idea as a working hypothesis leads to some unorthodox
and potentially fruitful approaches to familiar issues in
cognition. One of these issues, raised in the target article, is what
branch of mathematics will emerge as the most relevant to the
understanding of cognition in the near future. Shepard mentions in
this context group theory; the work of Tenenbaum and Griffiths
suggests that Bayesian methods will be useful. If the spatial
hypothesis is viable, cognitive scientists may also have to take up
Riemannian and algebraic geometry.  Another issue to consider is the
basic nature of the information processing in the brain.  Assuming
that the representations harbored by the brain are intrinsically
space-like, the model of computation best suited for the understanding
of cognition may be based on continuous mappings
[<A
 HREF="Shepard-commentary.html#MacLennan99field">MacLennan, 1999</A>], rather than on symbol manipulation. Finally,
one may inquire as to the form of the laws of cognition that can be
expected to arise most naturally from the NS hypothesis.  The law of
generalization proposed by Shepard (1987)  is an
important first step towards an answer to this question.

<P>

<H4><A NAME="SECTION00000040000000000000">
Challenges.</A>
</H4> The two most serious challenges for the NS
framework both stem from varieties of holism, albeit rather different
ones. First, representing an entire object or event by a point in a
neural space precludes the possibility of acting on, or even becoming
aware of, its structure [<A
 HREF="Shepard-commentary.html#Hummel00">Hummel, 2000</A>].  Second, the treatment of an
object by the cognitive system frequently depends on the context
within which the particular problem at hand is situated, and
therefore, potentially, on any of the totality of the representations
that exist in the system; this observation is used by [<A
 HREF="Shepard-commentary.html#Fodor00">Fodor, 2000</A>]
to argue for some very severe limitations on the scope of
``computational psychology.''  It appears to me that both these
problems can be addressed within the NS framework. Specifically,
adopting a configuration space approach, in which the global
representation space approximates the Cartesian product of spaces that
code object fragments [<A
 HREF="Shepard-commentary.html#EdelmanIntrator00sv">Edelman and Intrator, 2000</A>], may do away with the
unwanted holism in the representation of individual objects.
Furthermore, sharing the representation of an object among several
neural spaces may support its context-sensitive treatment (as long as
the spaces intersect transversally, they can be kept distinct in
places away from the intersection). This would allow the system to
make the kind of non-compositional, holistic inferences which, as
Fodor rightly notes, abound in human cognition.

<P>

<H2><A NAME="SECTION00000050000000000000">
Bibliography</A>
</H2><DL COMPACT><DD><P></P><DT><A NAME="ChurchlandSejnowski92">Churchland and Sejnowski, 1992</A>
<DD>
Churchland, P.&nbsp;S. and Sejnowski, T.&nbsp;J. (1992).
<BR><EM>The Computational Brain</EM>.
<BR>MIT Press, Cambridge, MA.

<P></P><DT><A NAME="CorteseDyre96">Cortese and Dyre, 1996</A>
<DD>
Cortese, J.&nbsp;M. and Dyre, B.&nbsp;P. (1996).
<BR>Perceptual similarity of shapes generated from Fourier
  Descriptors.
<BR><EM>Journal of Experimental Psychology: Human Perception and
  Performance</EM>, 22:133-143.

<P></P><DT><A NAME="CutzuEdelman96pnas">Cutzu and Edelman, 1996</A>
<DD>
Cutzu, F. and Edelman, S. (1996).
<BR>Faithful representation of similarities among three-dimensional
  shapes in human vision.
<BR><EM>Proceedings of the National Academy of Science</EM>,
  93:12046-12050.

<P></P><DT><A NAME="Edelman99book">Edelman, 1999</A>
<DD>
Edelman, S. (1999).
<BR><EM>Representation and recognition in vision</EM>.
<BR>MIT Press, Cambridge, MA.

<P></P><DT><A NAME="EdelmanEtAl98fmri">Edelman et&nbsp;al., 1999</A>
<DD>
Edelman, S., Grill-Spector, K., Kushnir, T., and Malach, R. (1999).
<BR>Towards direct visualization of the internal shape representation
  space by fMRI.
<BR><EM>Psychobiology</EM>, 26:309-321.

<P></P><DT><A NAME="EdelmanIntrator00sv">Edelman and Intrator, 2000</A>
<DD>
Edelman, S. and Intrator, N. (2000).
<BR>(Coarse Coding of Shape Fragments) + (Retinotopy) ~=
  Representation of Structure.
<BR><EM>Spatial Vision</EM>, -:-.
<BR>in press.

<P></P><DT><A NAME="Fodor00">Fodor, 2000</A>
<DD>
Fodor, J. (2000).
<BR><EM>The mind doesn't work that way</EM>.
<BR>MIT Press, Cambridge, MA.

<P></P><DT><A NAME="Gallistel90">Gallistel, 1990</A>
<DD>
Gallistel, C.&nbsp;R. (1990).
<BR><EM>The organization of learning</EM>.
<BR>MIT Press, Cambridge, MA.

<P></P><DT><A NAME="Gardenfors00">G&#228;rdenfors, 2000</A>
<DD>
G&#228;rdenfors, P. (2000).
<BR><EM>Conceptual spaces: the geometry of thought</EM>.
<BR>MIT Press, Cambridge, MA.

<P></P><DT><A NAME="GeorgopoulosEtAl88">Georgopoulos et&nbsp;al., 1988</A>
<DD>
Georgopoulos, A., Lurito, J.&nbsp;T., Petrides, M., Schwartz, A.&nbsp;B., and Massey,
  J.&nbsp;T. (1988).
<BR>Mental rotation of the neuronal population vector.
<BR><EM>Science</EM>, 243:234-236.

<P></P><DT><A NAME="Hummel00">Hummel, 2000</A>
<DD>
Hummel, J.&nbsp;E. (2000).
<BR>Where view-based theories of human object recognition break down: the
  role of structure in human shape perception.
<BR>In Dietrich, E. and Markman, A., editors, <EM>Cognitive Dynamics:
  conceptual change in humans and machines</EM>, chapter&nbsp;7. Erlbaum, Hillsdale, NJ.

<P></P><DT><A NAME="LandauerDumais97">Landauer and Dumais, 1997</A>
<DD>
Landauer, T.&nbsp;K. and Dumais, S.&nbsp;T. (1997).
<BR>A solution to Plato's problem: the latent semantic analysis theory
  of acquisition, induction, and representation of knowledge.
<BR><EM>Psychological Review</EM>, 104:211-240.

<P></P><DT><A NAME="MacLennan99field">MacLennan, 1999</A>
<DD>
MacLennan, B. (1999).
<BR>Field computation in natural and artificial intelligence.
<BR><EM>Information Sciences</EM>, 119:73-89.

<P></P><DT><A NAME="Marr70">Marr, 1970</A>
<DD>
Marr, D. (1970).
<BR>A theory for cerebral neocortex.
<BR><EM>Proceedings of the Royal Society of London B</EM>, 176:161-234.

<P></P><DT><A NAME="Mumford94">Mumford, 1994</A>
<DD>
Mumford, D. (1994).
<BR>Neuronal architectures for pattern-theoretic problems.
<BR>In Koch, C. and Davis, J.&nbsp;L., editors, <EM>Large-scale neuronal
  theories of the brain</EM>, chapter&nbsp;7, pages 125-152. MIT Press, Cambridge, MA.

<P></P><DT><A NAME="Shepard87">Shepard, 1987</A>
<DD>
Shepard, R.&nbsp;N. (1987).
<BR>Toward a universal law of generalization for psychological science.
<BR><EM>Science</EM>, 237:1317-1323.

<P></P><DT><A NAME="ShepardCermak73">Shepard and Cermak, 1973</A>
<DD>
Shepard, R.&nbsp;N. and Cermak, G.&nbsp;W. (1973).
<BR>Perceptual-cognitive explorations of a toroidal set of free-form
  stimuli.
<BR><EM>Cognitive Psychology</EM>, 4:351-377.

<P></P><DT><A NAME="ShepardChipman70">Shepard and Chipman, 1970</A>
<DD>
Shepard, R.&nbsp;N. and Chipman, S. (1970).
<BR>Second-order isomorphism of internal representations: Shapes of
  states.
<BR><EM>Cognitive Psychology</EM>, 1:1-17.

<P></P><DT><A NAME="Tversky77">Tversky, 1977</A>
<DD>
Tversky, A. (1977).
<BR>Features of similarity.
<BR><EM>Psychological Review</EM>, 84:327-352.
</DL>

<P>

<hr>
<DL>
<DT><A NAME="foot38">... Hypothesis</A><A NAME="foot38"
 HREF="Shepard-commentary.html#tex2html2"><SUP>1</SUP></A>
<DD> ``Where instances of a
particular collection of intrinsic properties (i.e., properties
already diagnosed from sensory information) tend to be grouped such
that if some are present, most are, then other useful properties are
likely to exist which generalize over such instances. Further,
properties often are grouped in this way.'' [<A
 HREF="Shepard-commentary.html#Marr70">Marr, 1970</A>].

<DT><A NAME="foot39">... spaces.''</A><A NAME="foot39"
 HREF="Shepard-commentary.html#tex2html3"><SUP>2</SUP></A>
<DD>Arguments against this idea
based on the observation that perceived similarities can be
asymmetrical [<A
 HREF="Shepard-commentary.html#Tversky77">Tversky, 1977</A>] is effectively countered, for example,
by adopting the Bayesian interpretation of Shepard's approach proposed
by Tenenbaum and Griffiths (this volume). Sticking with the physical
space metaphor, one can imagine a foliated, curved neural space,
riddled with wormholes (corresponding to arbitrary associations
between otherwise unrelated objects or concepts).  

</DL><HR>

<!-- hhmts start -->
Last modified on Mon Nov 27 10:48:42 2000
<!-- hhmts end -->

<!-- doc-lang: english -->
</BODY>
</HTML>
