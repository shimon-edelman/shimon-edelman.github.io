<?xml version="1.0" encoding="utf-8"?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 w-12-1</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2014-2022 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 12.1 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych 3140/6140</h1>
    <p><a href="http://shimon-edelman.github.io">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 12: neurons, II</h2>
    <h3>&nbsp;Lecture 12.1: learning</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->




<div  CLASS="slide">
  <h1>Lecture 12.1: learning via synaptic modification</h1>

  <P>
  <ul>
    <li>computational models of synaptic learning:
    <ul>
      <li>the Hebb rule and the Oja rule</li>
      <P>
      <li>the BCM rule / projection pursuit</li>
    </ul>
    </li>
      <P>
	<li>biological relevance of the BCM rule</li>
      </ul>
    </P>
  
</div>



<DIV  CLASS="slide">
  <h1>a by-now-unnecessary reminder: how a neuron computes</h1>

  <P>
    The basic <SC><B>computation</B></SC> performed by a neuron:
    <OL>
      <li>multiply the components of the incoming signal
	\(\textbf{x}=(x_1,x_2,\dots,x_i)\) by their corresponding
	synaptic <SC>weights</SC>, \(\textbf{w}=(w_1,w_2,\dots,w_i)\)</li>
      <li><SC>sum</SC> the resulting products;</li>
      <li>pass the sum through a <SC>nonlinearity</SC>
	(e.g., <a href="http://en.wikipedia.org/wiki/Logistic_sigmoid"
		  target=new>logistic sigmoid</a>);</li>
      <li><SC>compare</SC> the result to a <SC>threshold</SC>;</li>
      <li><SC><B>if</B></SC> it exceeds the threshold,
	<B><SC>then</SC></B> output an
	<SC><a href="http://en.wikipedia.org/wiki/Action_potential" target=new>action
	    potential</a></SC> (spike).</li>
    </OL>
  </P>

</div>


  <DIV  CLASS="slide">
  <h1>how neurons learn: experience driving the changes</h1>

  <img src="synaptic-plasticity.jpg" class="figure-right" height=500>
  <P>
    In many types of neurons, the synaptic weight \(\textbf{w}\)
    is <SC>modifiable</SC> by <SC><B>experience</B></SC> (and so are
    some of the parameters that control this modification process; see
    slides #10-#11).
  </P>
  <P>
    <a
      href="http://en.wikipedia.org/wiki/Synaptic_plasticity"
      target=new>Synaptic modification</a> can take the form of
    <SC>Long-Term Potentiation</SC>
    (<a href="http://en.wikipedia.org/wiki/Long-term_potentiation"
	target=new>LTP</a>) or <SC>Long-Term Depression</SC> 
    (<a href="http://en.wikipedia.org/wiki/Long-term_depression"
	target=new>LTD</a>) of synaptic efficacy (weight).
  </P>
  <P class="incremental">
    The details of these processes — even the vastly oversimplified
    sketch of the molecular dynamics of LTP and LTD illustrated here — are beyond the
    scope of the present discussion.
  </P>
  <HR>  
  <P class="incremental">
    <font color=red><SC><B>Experience</B></SC> = joint
      <a href="http://en.wikipedia.org/wiki/Statistics"
	 target=new><SC><B>statistics</B></SC></a> of presynaptic and postsynaptic 
      neuron activities.</font>
  </P>

</DIV>


<DIV  CLASS="slide">
  <h1>a reminder re the neuron's "experience": the War Room analogy</h1>

  <a href="http://en.wikipedia.org/wiki/Dr._Strangelove"
     target=new><img src="strangelove_war_room.jpg"
		     title="the war room from Dr. Strangelove"
		     height=250 class="figure-right"></a>
  <P>
    <font color=red><SC><B>Experience</B></SC> = joint
      <a href="http://en.wikipedia.org/wiki/Statistics"
	 target=new><SC><B>statistics</B></SC></a> of presynaptic and postsynaptic 
      neuron activities.</font>
  </P>
  <P>  
    Why it makes sense to define experience in terms of synapse-level events:
    <DIR><DIR>
	— remember the analogy between the brain/mind and a war cabinet.
    </DIR></DIR>
  </P>
    <P>  
      Why it makes sense to consider experience through the lens of statistics:
      <DIR><DIR>
	  — review material from weeks 1 through 10 :-)
      </DIR></DIR>
    </P>
    <P>
      Why JOINT INPUT&OUTPUT statistics?
      <DIR><DIR>
	  — because consequences matter (in reinforcement learning,
	  consequences of actions; here, of neural activity)  
      </DIR></DIR>
    </P>

</DIV>




<DIV  CLASS="slide">
  <h1>ASH NAZG...</h1>

  <P>
    ONE RULE TO BRING THEM ALL:
    <DIR>      <DIR>      <DIR>
	  The  <a 
		 href="http://en.wikipedia.org/wiki/Hebbian"
		 target=new><SC>Hebbian</SC></A> rule: "neurons that fire together,
	  wire together".
    </DIR>      </DIR>      </DIR>
  </P>
  <P class="incremental">
    [That's roughly speaking. There's a lot of nuance to it.]
  </P>

</div>


      

<DIV  CLASS="slide">
  <h1>input space and weight space, visualized together</h1>

  <img src="Hebb-cloud.jpg" class="figure-right" height=350>
  <P>
    Consider a neuron that computes
    $$
    y = \textbf{w}\cdot \textbf{x} = w_1 x_1 + w_2 x_2
    $$
  </P>
  <HR>
  <P>
    On the right, the input \(\textbf{x}=(x_1,x_2)\) and the weight
    \(\textbf{w}=(w_1,w_2)\) vectors are plotted together in the same
    2D space. The dotted line shows the change that the weight vector
    undergoes through Hebbian learning (see next slide).
  </P>
  <P>
    In the plot here, the horizontal and vertical axes are for
    \((x_1,x_2)\), which is the input space, <B>and</B> for
    \((w_1,w_2)\), which is the weight space.
  </P>

</div>


<DIV  CLASS="slide">
  <h1>input/output statistics driving weight changes</h1>

  <img src="Hebb-cloud.jpg" class="figure-right" height=350>
  <P>
    Consider a neuron that computes
    $$
    y = \textbf{w}\cdot \textbf{x} = w_1 x_1 + w_2 x_2
    $$
  </P>
  <P>
    Computational analysis carried out in the 1980s<SUP>*</SUP> showed that
    neurons with
    experience-dependent <a href="http://en.wikipedia.org/wiki/Hebbian"
    target=new><SC>Hebbian</SC></A> synapses (as in: spike timing
    dependent
    plasticity, <a href="http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity"
    target=new>STDP</a>, to be discussed later this week) learn the
    projection that maximizes the
    <a href="https://en.wikipedia.org/wiki/Variance"
    target=new>variance</a> of the data in the resulting space. In
    other words, they carry out Principal Component Analysis
    or <a href="http://en.wikipedia.org/wiki/Principal_component_analysis"
    target=new>PCA</a>.
  </P>
  <P>
    In the plot here, the horizontal and vertical axes are for
    \((x_1,x_2)\) <B>and</B> \((w_1,w_2)\).
  </P>
  <HR>
  <P>
    <small>
      <SUP>*</SUP> Sanger, T. D. (1989).
      <a href="https://courses.cs.washington.edu/courses/cse528/09sp/sanger_pca_nn.pdf"
      target=new><I>Optimal unsupervised learning in a single-layer
      linear feedforward neural network</I></a>. Neural Networks
	2:459-473.
      </small>
    </P>

</div>


<!-- Hebb and BCM -->


  

<DIV CLASS="slide">
  <h1>the Hebb rule and Oja's modification of it</h1>

  <P>
    <B>Hebbian learning:</B> a synaptic connection between two neurons
    increases in efficacy in proportion to the degree of
    <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
    target=new>correlation</a> between the mean activities of the pre-
    and post-synaptic neurons
    (<a href="http://scholarpedia.org/article/Hebb" target=new>Donald
    O. Hebb</a>, 1949).
  </P>
  <P>
    The <a href="https://en.wikipedia.org/wiki/Hebbian_theory"
	   target=new>Hebb rule</a> in formal notation: the rate of
	   change (time
	   <a href="https://en.wikipedia.org/wiki/Derivative"
	   target=new>derivative</a>) of the weight \(w_i\) is 
	   proportional to the product of the input \(x_i\) and output
	   \(y\) — 
    $$
    \begin{matrix}
    y &=& \sum_i w_i x_i \\
    \frac{dw_i}{dt} &=& \eta x_i y
    \end{matrix}
    $$
    The <a href="http://scholarpedia.org/article/Oja_learning_rule"
	   target=new>Oja rule</a>:
    $$
    \frac{dw_i}{dt} = \eta \left(x_i y - y^2w_i\right)
    $$
  </P>

</div>




<DIV CLASS="slide">
  <h1>an axiomatic approach to modeling synaptic modification, leading
  to the BCM rule (after Cooper & Bear 2012)</h1>

  <P>
    To account for much data on synapse modification in response to
    experience, Bienenstock,
    <a href="http://en.wikipedia.org/wiki/Leon_Cooper" target=new>Cooper</a>, and
    Munro (1982) proposed the three 
    postulates of what came to be called the
    <a href="http://scholarpedia.org/article/BCM_rule" target=new>BCM theory</a>:
    <ol>
      <li>The change in synaptic weights (\(dw_i/dt\)) is proportional to
	the PREsynaptic activity (\(x_i\)).
      </li>
      <li>The change in synaptic weights (\(dw_i/dt\)) is also proportional to a non-monotonic
	function (denoted by \(\phi\)) of the POSTsynaptic activity (\(y\)): 
	<ol>
	  <li>for small \(y\) , the synaptic weight decreases
	    (\(dw_i/dt < 0\));
			 </li>
	  <li>for larger \(y\) , it increases (\(dw_i/dt > 0\)).
	    </ol>
	    The cross-over point between \(dw_i/dt < 0\) and \(dw_i/dt > 0\) is called the
	      modification threshold, and is denoted by \(\theta_M\).
	    </li>
	  <li>
	    The modification threshold \(\theta_M\) is itself a nonlinear
	    function of the history of postsynaptic activity \(y\). 
	  </ol>
	  </P>
	  <HR>
	    <P class="incremental">
	      Principle (2) implies that "the rich [the already strong
	      synapses] get richer and the poor get poorer."
	    </P>
  
</div>

  

<DIV CLASS="slide">
  <h1>an objective-function formulation of BCM & dimensionality
  reduction by Projection Pursuit</h1>

  <img src="BCM_Main_figure.png" class="figure-right" height=250>
  <P>
    The BCM rule (Intrator and Cooper, 1992):
    $$
    \begin{matrix}
    y &=& \sigma\left(\sum_i w_i x_i\right) & \ \\
    \frac{dw_i}{dt} &\propto & \phi\left(y\right)\cdot x_i &= y\left(y-\theta_M\right)\cdot x_i \\
    \theta_M &=& E\left[y^2\right] & \ 
    \end{matrix}
    $$
    where \(E\) denotes <a href="http://en.wikipedia.org/wiki/Expected_value"
			   target=new>expectation</a> (statistical averaging).
  <!-- \cdot
 \sigma^{\prime}\left(y\right) and
  \(\sigma^{\prime}\) is the derivative of the sigmoidal transfer function \(\sigma\)
  (the neuron's "output nonlinearity").
    -->
  </P>
  <P>
    This form of BCM can be derived by minimizing a loss (or objective,
    or cost) function
    $$
    R = -\frac{1}{3} E\left[y^3\right] + \frac{1}{4}E^2\left[y^2\right]
    $$
    that measures the
    <a href="https://en.wikipedia.org/wiki/Multimodal_distribution"
    target=new><B>bi-modality</B></a> of the output distribution. 
    Similar rules can be derived from objective functions based on
    <a href="http://en.wikipedia.org/wiki/Kurtosis" target=new>kurtosis</a> and
    <a href="http://en.wikipedia.org/wiki/Skewness" target=new>skewness</a>. 
  </P>
  <P class="incremental">
    The overarching goal:
    <a href="https://www.jstor.org/stable/2241175" target=new>seek
    interesting projections</a> — those characterized by a far from
    the
    <a href="https://en.wikipedia.org/wiki/Normal_distribution"
    target=new>normal distribution</a> (the
    <a href="https://en.wikipedia.org/wiki/Central_limit_theorem"
    target=new>Central Limit Theorem</a> suggests that projections of
    a cloud of random points in hi-dim tend to be normal).
  </P>
  
</div>


<DIV CLASS="slide">
  <h1>the conceptual steps in getting from Hebb (a) to BCM (d)</h1>

  <img src="CooperBear12-fig1.png" class="figure-right" height=300>
  <P>
  <B>(a)</B> For the information required for Hebbian synaptic modification
  to be available <B>locally</B> at the synapses, information about the
  integrated postsynaptic firing rate \(c\) must be propagated backwards or
  retrogradely. The existence of 'back spiking' (dashed lines) was confirmed
  experimentally and shown to be associated with changes in synaptic
 strength.
  <P>
  <B>(b)</B> Simple Hebbian modification assumes that active synapses grow
  stronger at a rate proportional to the concurrent integrated postsynaptic
  response; therefore, the value of \(\phi\) increases monotonically with
  \(c\).
  <P>
  <B>(c)</B> The CLO (Cooper, Liberman, and Oja) theory combined Hebbian and
  anti-Hebbian learning to obtain a more general rule that can yield
  selective responses. When a pattern of input activity evokes a
  postsynaptic response greater than the modification threshold
  (\(\theta_m\)), the active synapses strengthen; otherwise, the active
  synapses weaken.
  <P>
  <B>(d)</B> The BCM (Bienenstock, Cooper and Munro) theory incorporates
  a sliding modification threshold that adjusts as a function of the history
  of average activity in the postsynaptic neuron. This graph shows the shape
  of \(\phi\) at two different values of \(\theta_m\). The orange curve
  shows how synapses modify after a period of postsynaptic inactivity, and
 the red curve shows how synapses modify after a period of heightened
  postsynaptic activity.
  
</div>

    

<DIV CLASS="slide">
  <h1>the important properties of the BCM rule (Intrator and Cooper, 1992)</h1>

  <ol>
    <li>
    As an exploratory projection index, it seeks deviation from a
    Gaussian distribution, in the form of multi-modality.
    </li>
    <li>
    It naturally extends to a lateral inhibition network, which can find
    several projections at once.
    </li>
    <li>
    The number of calculations of the gradient grows linearly with the
    number of projections sought, thus it is very efficient in high dimensional
    feature extraction.
    </li>
    <li>
    The search is forced
    to <a href="http://en.wikipedia.org/wiki/Projection_pursuit"
    target=new>seek projections</a> that are orthogonal to all but one
    of the \(K\) clusterings (in the original space). Thus, there are
    at most \(K\) optimal projections and not \(K(K−1)/2\) separating
    hyper-planes as in discriminant analysis methods. This property is
    very important as it suggests why the "curse of dimensionality" is
    less problematic with this learning rule.
    </li>
    <li>
      <font color=gray>[EXTRA] The neuronal output (or the projection) of an input \(x\) (or a
    cluster of inputs) is proportional to \(1/P(x)\), where \(P(x)\)
    is the a-priori probability of the input \(x\). This property is
    (1) essential for creating
    <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.1269"
    target=new><B>"suspicious coincidence" detectors</B></a>, and (2)
    it also indicates the optimality of the learning rule in terms of
    energy (or code) conservation.  If a biologically plausible
    logarithmic saturation transfer function is used as the neuronal
    nonlinearity, it follows that the amplitude or
    <a href="https://en.wikipedia.org/wiki/Variable-length_code"
    target=new>code length</a> associated with the input \(x\) is
    proportional to \(−\log\left(P\left(x\right)\right)\), which is
    optimal from
    <a href="https://en.wikipedia.org/wiki/Information_theory"
       target=new>information-theoretic</a> considerations.
    </font>
    </li>
  </ol>

  
</div>

  


<!--

<DIV CLASS="slide">
  <h1>Can theory be useful in neuroscience? (Cooper and Bear, 2012)</h1>

  <P>
  <BR>
  What is a good theory? The usefulness of a theory lies in its concreteness and in the precision
with which questions can be formulated. A successful approach is to find the minimum number of
assumptions that imply as logical consequences the qualitative features of the system that we are
trying to describe. As Einstein is reputed to have said: “Make things as simple as possible, but no
simpler.” Of course there are risks in this approach. We may simplify too much or in the wrong way
so that we leave out something essential or we may choose to ignore some facets of the data that
distinguished scientists have spent their lifetimes elucidating. Nonetheless, the theoretician must
first limit the domain of the investigation: that is, introduce a set of assumptions specific enough to
give consequences that can be compared with observation. We must be able to see our way from
assumptions to conclusions. The next step is experimental: to assess the validity of the underlying
assumptions if possible and to test predicted consequences.
  <P>
A ‘correct’ theory is not necessarily a good theory. For example, in analysing a system as
complicated as a neuron, we must not try to include everything too soon. Theories involving vast
numbers of neurons or large numbers of parameters can lead to systems of equations that defy
analysis. Their fault is not that what they contain is incorrect, but that they contain too much.
<P>
  A theory is not a legal document and, in spite of occasional suggestions to the contrary, no
scientist is in communication with the Almighty. Theoretical analysis is an ongoing attempt to
create a structure — changing it when necessary — that finally arrives at consequences consistent
with our experience. Indeed, one characteristic of a good theory is that one can modify the
structure and know what the consequences will be. From the point of view of an experimentalist, a
good theory provides a structure in to which seemingly incongruous data can be incorporated and
that suggests new experiments to assess the validity of this structure. A good theory helps the
experimentalist to decide which questions are the most important.

  </div>

  -->


<DIV CLASS="slide">
  <h1>lessons?</h1>

  <!--   <img src="" class="figure-right" >  -->
  <P>
    So, what is it that neurons compute (natively)?
    <ul class="incremental">
    <li>
      Do linear algebra (vector projection / inner product, matrix
      multiplication).</li>
    <li>
      Implement dimensionality reduction (from many dimensions to one),
      <font color=gray>including similarity-preserving DR by random projections.</font>
    </li>
    <li>
      <font color=gray>Perform function approximation (when arranged
      in multilayer networks).</font> 
    </li>
    <li>
      Respond selectively (exhibit tuning) [and thus
	serve as landmarks/prototypes in a similarity-based
	representation scheme, a.k.a. the Chorus Transform].
    </li>
    <li>
      Form spatial maps, presumably to facilitate navigation, episodic
      memory and prospection, and social cognition.
    </li>
    <li>
      Form abstract maps (retinotopic, tonotopic, chronotopic, etc.),
      presumably to facilitate similarity-based readout. 
    </li>
    <li>
      Organize themselves in dynamic assemblies (note the importance of
      time) implemented by readout mechanisms.
    </li>
    <li>
      Collectively generate oscillating local electrical fields and
      interact with these fields to implement attention etc.
    </li>
    <li>
      Learn.
    </li>
    </ul>
  </P>
  
</div>

  
<div class="footer">
<p>Last modified: Tue Apr 19 2022 at 09:15:04 EDT</p>
</div>
</body>
</html>
