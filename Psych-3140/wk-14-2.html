<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 wk-14-2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2014-2022 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 15.1 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych 3140/6140</h1>
    <p><a href="http://shimon-edelman.github.io">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 14: advanced topics</h2>
    <h3>&nbsp;Lecture 14.2: emotions</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->


<div  CLASS="slide">
  <h1>Lecture 14.2: emotions</h1>

  <img src="Minsky-emotion-machine-cover.jpg" height=500
  class="figure-right">
  <P>
    <B>Emotions</B> (an algorithmic take):
  </P>
  <P>
    <I>Algorithms for survival: a comparative perspective on emotions</I>, 
    D. R. Bach and P. Dayan, Nature Reviews Neuroscience 18:311-319 (May
    2017).
  </P>

  <P class="incremental">
    Executive summary: moah Bayesian shortcuts!
  </P>

  
</div>



<div CLASS="slide">
  <h1>algorithms for emotions (Bach & Dayan, 2017): optimality and intractability</h1>

  <P>
    "The nature and neural implementation of emotions is the subject of
    vigorous debate. Here, we use Bayesian decision theory to address key 
    complexities in this field and conceptualize emotions in terms of their
    relationship to survival-relevant behavioural choices.
  </P>
  <P>
    Decision theory indicates which behaviours are OPTIMAL in a given
    situation; however, the calculations required are radically
    INTRACTABLE. We therefore conjecture that the brain uses a range
    of pre-programmed algorithms that provide approximate
    solutions. These solutions seem to produce specific behavioural
    manifestations of emotions and can also be associated with core
    affective dimensions."
  </P>

</div>



<div CLASS="slide">
  <h1>algorithms for emotions (Bach & Dayan, 2017): the levels of analysis</h1>

  <P>
    "We seek to circumvent the quandaries that are associated with the
    definitions of emotion.  Instead, acknowledging that we eschew
    <a href="https://plato.stanford.edu/entries/qualia/"
       target=new>qualia</a> (the joyfulness of joy, the fearfulness
       of fear, and so on), we use decision theory to describe three
       facets of the determinants of behaviour in specific situations
       that lead to phenomena that are often classed as being
    emotional."
  <ul class="incremental">
    <li>
    A COMPUTATIONAL analysis of the goals that humans and
    other animals pursue when making choices
    in natural environments and of the actions
    that may be needed to achieve such goals.
    </li>
    <li>
    An ALGORITHMIC analysis of the procedures that would allow an agent  
    to decide on these actions. We describe
    specific exemplars of algorithms that seem to
    control phenomena that are often associated
    with emotions.
    </li>
    <li>
    <font color=gray>An IMPLEMENTATIONAL analysis of the possible
    neural substrates of these decision-making
    algorithms.</font>
    </li>
  </ul>
  </P>

</div>


<div CLASS="slide">
  <h1>simplifying optimal choice: preprogramming, diversification</h1>

  <P>
    Bayesian decision theory (BDT) provides a compelling
    computational-level prescription of adaptive behaviour. However,
    it suffers from STATISTICAL COMPLEXITY in its requirement for a
    large amount of information in novel environments to produce good
    trajectories of choices and from CALCULATIONAL COMPLEXITY in the
    assessment of the expected worth of those choices.
  </P>
  <P>
    The brain seems to have adopted two major simplifications to
    approximate optimal choice. Both simplifications are germane to
    emotions.
  </P>
  <P>
    <ol>
      <li>
	Use partly pre-programmed algorithms to make these
	choices; the algorithms may differ
	<ol>
	  <li>in the inputs that they consider,</li>
	  <li>in the extent to which they are plastic, and</li>
	  <li>in the breadth of actions that they arbitrate.</li>
	</ol>
      </li>
      <li>
	Combine multiple different sorts of algorithm, each of which
	excels in a different regime of training time and required
	speed.
      </li>
    </ol>
  </P>

</div>
  


<div CLASS="slide">
  <h1>challenge #1 to the Bayesian Decision Theory (BDT): defining utility</h1>

  <P>
    UTILITY FUNCTIONS. The first conceptual problem in BDT is a
    quantification of the costs and benefits that are associated with
    particular outcomes — this is called a utility function.
  </P>
  <P>
    Evolutionary precepts suggest that the goal for an individual’s
    preferences should be to prioritize reproductive fitness,
    including one’s own and relatives’ survival. However, practically,
    this metric is unusably long-term. Simpler, more immediate ones
    must be used.
  </P>

</div>


<div CLASS="slide">
  <h1>challenge #2 to BDT: limited information</h1>

  <P>
    LIMITED INFORMATION. The next conceptual problem arises when
    biological agents have very limited information about very complex
    environments and, at the same time, when exploratory actions are
    dangerous, for instance in the face of mortal threat, starvation
    or dehydration. There are particularly severe computational costs
    attached to the standard decision-theoretic approach of building
    hierarchical Bayesian models in which this ignorance about aspects
    of the model is treated as itself being just another form of
    uncertainty.
  </P>
  <P>
    One apparent solution to this conundrum is pre-programming: we
    argue that there are restrictive prior distributions that specify
    what to expect in the environment and constrained policies that
    map observations to actions. The pre-specification and the
    constraints obviate the costs of learning and computation.
  </P>

</div>


<div CLASS="slide">
  <h1>challenge #3 to BDT: the range of actions</h1>

  <P>
    ACTION REPERTOIRE. The final conceptual question relates to the
    set of actions that are available to the agent. In conventional
    applications of BDT, this set is of modest size and fully known to
    the agent.  However, in natural environments, the range of
    possible effective actions can be overwhelming and is at least
    partly not known.
  </P>
  <P>
    To solve this problem, the agent could compute with a limited
    action menu that is pre-programmed and/or is transferrable from
    previous learning.
  </P>

</div>
  


<div CLASS="slide">
  <h1>a computational obstacle for BDT: intractability</h1>

  <P>
    Along with the conceptual problems described above, another
    problem for BDT is its FORMAL INTRACTABILITY: the required
    computations can rarely be performed with viable amounts of time
    and/or require more storage than is realistically available.
  </P>
  <P>
    A number of generic approximations have therefore been
    proposed. Specific exemplars of these approximations seem to
    govern
    <a href="https://www.nature.com/articles/nrn.2018.22"
       target=new>behaviour under threat</a>. It is <B>important</B>
       to note that these particular algorithms are NOT simple or
    transparent consequences of BDT itself.
  </P>

</div>
  

<div CLASS="slide">
  <h1>control algorithms for survival: Pavlovian/operant, model-free/model-based</h1>

  <P>
    Control algorithms are characterizations of ways that an agent — a
    machine or an animal — can determine appropriate
    actions. Efficient control algorithms approximate BDT as closely
    as possible while minimizing computational costs.  Such algorithms
    can be classified along two orthogonal fault-lines.
  </P>
  <P>
    One concerns action contingency and is associated with the
    distinction
    between <a href="https://en.wikipedia.org/wiki/Classical_conditioning"
    target=new>Pavlovian</a> and
    <a href="https://en.wikipedia.org/wiki/Operant_conditioning"
       target=new>instrumental</a> (or operant) control.
  </P>
  <P>
    The other concerns prospective versus retrospective prediction
    about the future and is associated with the distinction between
    model-based and model-free control.
  </P>
  <P class="incremental">
    A reminder:
    <BR> model-free = select action on the basis of past
      action/reward experience;
      <BR> model-based = select action on the basis of
	future-projected run of a model of the world.
      </P>

</div>


<div CLASS="slide">
  <h1>algorithms for various types of behavior: consummatory vs. preparatory</h1>

  <P>
    Various behaviours seem to be controlled by distinct algorithms
    that have different pre-programming characteristics and may thus
    potentially represent separate controllers.
  </P>
  <P>
    CONSUMMATORY ACTIONS.  Consummatory responses — instincts, or
    fixed action patterns — occur in the presence of evidently
    significant events, such as imminent or proximal threat. They seem
    to be substantially pre-programmed; however, they are not
    hard-wired to the extent that activation of an algorithm leads to
    the same action pattern every time.
  </P>
  <P>
    PREPARATORY ACTIONS. When significant events are not yet present
    but can be predicted from innate or learned precursors,
    preparatory controllers enter the frame.  These often exhibit a
    substantial degree of plasticity.
  </P>

</div>



<div CLASS="slide">
  <h1>resolving conflict between controllers: arbitration and anxiety</h1>

  <P>
    There may be direct <B>conflict</B> between different controllers’
    prescriptions, for instance, between Pavlovian and instrumental
    mechanisms for achieving the same goal or between controllers
    advocating approach and avoidance (for example, when foraging in
    conditions of both hunger and threat).
  </P>
  <P>
    In the latter case, the dedicated action pattern that is adopted
    to resolve such conflict has been termed ‘ANXIETY-like’ and
    includes passive avoidance (that is, a complete lack of
    approach). In exploration or foraging paradigms, such avoidance
    gradually disappears over time. A related response in humans is
    anxiety-like behavioural inhibition, which has been suggested to
    be partly under instrumental, and possibly model-based, control.
  </P>
  <P class="incremental">
    In general, arbitration between controllers might happen via
      some <B>"common currency"</B> representations. For instance,
      model-free controllers by design attach scalar quantities to
      environmental states or actions. As such, the output of these
      controllers may be captured in a low-dimensional space with axes
      such as utility or VALENCE (mediating approach or withdrawal)
      and AROUSAL (mediating invigoration and inhibition).
  </P>

</div>



<div CLASS="slide">
  <h1>but what <I>are</I> feelings?</h1>

  <P>
    Two central questions: what are
    feelings? And what is their adaptive function?
  </P>
  <P>
    In terms of their nature, feelings might be meta-cognitive
    representations of the inner workings of decision-making
    systems. They would thus be constructed as the output of more
    basic psychological operations.
  </P>
  <P>
    Experienced (even incidental) feelings influence future decisions,
    as well as immediate actions.
  </P>
  <P>
    FIRST, there is a suggestion that moods can be understood as
    long-run averages of short-lasting feelings and that these moods
    could themselves have an enduring impact on future decisions,
    acting as forms of generic environmental priors
    [<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0153193"
	target=new>example</a>].
  </P>
  <P>
    SECOND, although decisions are shaped by currently experienced
    feelings, they are also influenced by the feelings that are
    anticipated to occur after relevant outcomes. Hence, feelings
    experienced in the past may provide sparse and efficient signals
    for future deliberation of decision outcomes and thus simplify
    model-based search and/or memory lookup.
  </P>

</div>  



<div CLASS="slide">
  <h1>what valence is</h1>

  <img src="Hesp21-cover.png" class="figure-right" height=450>
  <P>
    The positive-negative axis of emotional valence has long been
    recognized as fundamental to adaptive behavior, but its origin and
    underlying function have largely eluded formal theorizing and
    computational modeling.  Using deep active inference, a
    hierarchical inference scheme that rests on inverting a model of
    how sensory data are generated, we develop a principled <B>Bayesian
    model of emotional valence</B>. This formulation asserts that agents
    infer their valence state based on the expected precision of their
    action model — an internal estimate of overall model fitness
    (“subjective fitness”).
  </P>
  <P>
    This index of subjective fitness can be estimated within any
    environment and exploits the domain generality of second-order
    beliefs (beliefs about beliefs). We show how maintaining internal
    valence representations allows the ensuing affective agent to
    optimize confidence in action selection preemptively. Valence
    representations can in turn be optimized by leveraging the
    (Bayes-optimal) updating term for subjective fitness, which we
    label <B>affective charge</B> (AC). AC tracks changes in fitness
    estimates and lends a sign to otherwise unsigned divergences
    between predictions and outcomes.
  </P>

</div>



<div CLASS="slide">
  <h1>a reminder: active inference</h1>

  <img src="Hesp21-cover.png" class="figure-right" height=450>
    <P>
      Every living thing from bachelors to bacteria seeks glucose
      proactively— and does so long before internal stocks run out. As
      adaptive creatures, we seek outcomes that tend to promote our
      long-term functional and structural integrity (i.e., the
      well-bounded set of states that characterize our phenotypes).
      <B>That adaptive and anticipatory nature of biological life is
      the focus of the formal Bayesian framework called active
      inference.</B> This framework revolves around the notion that
      all living systems embody statistical models of their worlds
      (Friston, 2010; Gallagher & Allen, 2018). In this way, beliefs
      about the consequences of different possible actions can be
      evaluated against preferred (typically phenotype-congruent)
      consequences to inform action selection. In active inference,
      every organism enacts an implicit phenotype-congruent model of
      its embodied existence (Ramstead, Kirchhoff, Constant, &
      Friston, 2019; Hesp et al., 2019), which has been referred to as
      self-evidencing (Hohwy, 2016).
    </P>
    <P>
      Active inference formalizes our survival and procreation in
      terms of <B>a single imperative: to minimize the divergence
      between observed outcomes and phenotypically expected (i.e.,
      preferred) outcomes under a (generative) model that is
      fine-tuned over phylogeny and ontogeny</B> (Badcock, 2012;
      Badcock, Davey,Whittle, Allen, & Friston, 2017; Badcock,
      Friston, & Ramstead, 2019). This discrepancy can be quantified
      using an information-theoretic quantity called variational free
      energy (denoted F; see appendix A1; Friston, 2010). Tominimize
      free energy ismathematically equivalent to maximizing (a lower
      bound on) Bayesian model evidence, which quantifies model fit or
      subjective fitness; this contrasts with biological fitness,
      which is defined as actual reproductive success (Constant,
      Ramstead, Veissière, Campbell, & Friston, 2018).
    </P>

</div>    

  

<div CLASS="slide">
  <h1>generative model of perception and anticipation</h1>

  <img src="Hesp21-fig1.png" class="figure-right" height=450>
  <P>
    The first (\(M_1\), top panel) and second steps (\(M_2\), bottom
    panel) of a generative model of increasing complexity.
  </P>
  <P>
    \(M_1\): A minimal generative model of perception can infer hidden
    states \(s\) from an observation \(o\), based on prior beliefs
    (\(\textbf{D}\)) and a likelihood mapping (\(\textbf{A}\)).
  </P>
  <P>
    \(M_2\): A generative model of anticipation extends perception
    forward into the future (and backward into the past) using a
    transition matrix (\(\textbf{B}_{\tau}\)) for hidden states.
  </P>

</div>    

  
  

<div CLASS="slide">
  <h1>generative model of action</h1>

  <img src="Hesp21-fig2.png" class="figure-right" height=450>
    <P>
      In a generative model of action, state transitions are
      conditioned on policies \(\pi\).
    </P>
    <P>
      Prior policy beliefs \(\pi\) are informed by the baseline prior
      over policies (“model free,” denoted \(\textbf{E}_{\pi}\)) and
      the expected free energy (\(\textbf{G}_{\pi}\)), which evaluates
      each policy-specific perception model (as in \(M_2\)) in terms
      of the expected risk and ambiguity.  Risk biases the action
      model toward phenotype-congruent preferences
      (\(\textbf{C}\)).
    </P>
    <P>
      Posterior policy beliefs are informed by the fit between
      anticipated (policy-specific) and preferred outcomes, while at
      the same time minimizing their ambiguity.
    </P>

</div>    

  
  

<div CLASS="slide">
  <h1>generative model of implicit metacognition</h1>

  <img src="Hesp21-fig3.png" class="figure-right" height=450>
  <P>
    <B>This generative model infers confidence in its own action model
    in terms of the expected precision</B> (\(\gamma\)), which
    modulates reliance on \(\textbf{G}_{\pi}\) for policy selection
    (as in \(M_3\)), based on perceptual inferences (as in
    \(M_2\)). Expected precision (\(\gamma\)) changes when inferred
    policies differ from expected policies. This term increases when
    posterior (policy-averaged) expected free energy is lower than
    when averaged under the policy prior (\(AC = (\pi − \bar{\pi})
    \cdot \textbf{G}_{\pi} < 0\)), and decreases when it is higher
    (\(AC > 0\)).
  </P>
  <P>
    \(AC\) — affective charge — can only be nonzero when inferred
    policies differ from expected policies \(\pi \neq \bar{\pi}\). It
    is positive when perceptual evidence favors an agent’s action
    model and negative otherwise. In other words, <B>positive and
    negative AC corresponds, respectively, to increased and decreased
    confidence in one’s action model</B>. Accordingly, because
    \(\textbf{G}_{\pi}\) is a function of achieving preferred
    outcomes, \(AC\) can be construed as a reward prediction error,
    where reward is inversely proportional to \(\textbf{G}_{\pi}\)
    (Friston et al., 2014). For example, a predator may be confidently
    pleased with itself after spotting a prey (positive \(AC\)) and
    frustrated when it escapes (negative \(AC\)).
  </P>

</div>    

  
  

<div CLASS="slide">
  <h1>happiness is...</h1>

  <img src="blurry-happiness.jpg" class="figure-right" height=400>
  <P>
    
  </P>

</div>    


  
<div class="footer">
<p>Last modified: Wed May 4 2022 at 09:32:40 EDT</p>
</div>
</body>
</html>
