<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 wk-7-1</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2008-2024 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 8.1 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych 3140/6140</h1>
    <p><a href="http://shimon-edelman.github.io">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 7: actions and consequences</h2>
    <h3>&nbsp;Lecture 7.1: motor control</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->



<div  CLASS="slide">
  <h1>motor control</h1>

  <img src="cat-math-small.gif" class="figure-right" >
  <P>
  <ul>
    <li>The problem(s) of motor control</li>
    <P>
    <li>Motor control as an inverse problem; ill-posedness</li>
    <P>
    <li>The agonist/antagonist principle and force fields</li>
    <P>
    <li>Decision-making in motor control</li>
    <P>
    <li>The Bayesian perception/action loop</li>
  </ul>
  
</div>




<div  CLASS="slide">
  <h1>the problem(s) of motor control</h1>

  <img src="cat-math-small.gif" class="figure-right" height=350>
  <P>
    This cat cartoon is a very incomplete illustration of the problem of motor
    control, because a jump is ballistic (= hardly any control past the launch
    phase). 
  </P>
  <P>
    Generally, these are the aspects of control that must be addressed:
    <ol start=0 >
      <li>[local environment layout] geometry</li>
	<li>[body + immediate environment: the configuration] <a href="http://en.wikipedia.org/wiki/Kinematics" target=new>kinematics</a> and <a
															       href="http://en.wikipedia.org/wiki/Inverse_kinematics" target=new>inverse kinematics</a></li>
	<li>[body + immediate environment: the forces] <a href="http://en.wikipedia.org/wiki/Analytical_dynamics"
					 target=new>dynamics</a> and <a
								       href="http://en.wikipedia.org/wiki/Inverse_dynamics" target=new>inverse dynamics</a></li>
      </ol>
      <img src="forward-vs-inverse-problems.png" 
	   height=200>
  
</div>



<div  CLASS="slide">
  <h1>CAUSES of things</h1>

  <a
    href="https://en.wikipedia.org/wiki/Felix,_qui_potuit_rerum_cognoscere_causas"
    target=new><img src="felix-qui-potuit.jpg" class="figure-right"></a>
    <P>
      <a href="http://en.wikipedia.org/wiki/Felix,_qui_potuit_rerum_cognoscere_causas"
	 target=new>FELIX QUI POTUIT RERUM COGNOSCERE CAUSAS</a>
    </P>
    <P>
      happy is he, who knows the causes of things
    </P>
    <P>
      <ul class="outline">
	<li>in perception ("why?")
	  <ul>
	    <li>sensory</li>
	    <li>social</li>
	    <li>societal</li>
	  </ul>
	</li>
	<li>in action ("how to?")
	  <ul>
	    <li>motor</li>
	    <li>social</li>
	    <li>societal</li>
	  </ul>
	</li>
      </ul>
    </P>
  
</div>
      

<div  CLASS="slide">
  <h1>forward and inverse problems</h1>

    <P>
      Forward or direct problems: from causes to effects.
      <BR>
      Inverse problems: from effects to causes.
    </P>
    <P>
      <table>
	<tr>
	  <th>domain</th><th>forward</th><th>inverse</th>
	</tr>
	<tr>
	  <td>motor control of the arm</td>
	  <td>
	    <P>
	      <I>kinematics:</I> from [actual] joint angles to effector position
	    </P>
	    <P>
	      <I>dynamics:</I> from [actual] joint torques to effector force
	    </P>
	  </td>
	  <td>
	    <P>
	      <I>kinematics:</I> from [desired] effector position to joint angles
	    </P>
	    <P>
	      <I>dynamics:</I> from [desired] effector force joint torques
	    </P>
	  </td>
	</tr>
	<tr>
	  <td>vision</td>
	  <td>
	    <P>
	      <I>shape:</I> from surface shape to image intensities
	    </P>
	    <P>
	      <I>color:</I> from source spectrum and surface reflectance to image intensities
	    </P>
	  </td>
	  <td>
	    <P>
	      <I>shape:</I> from image intensities to surface shape
	    </P>
	    <P>
	      <I>color:</I> from image intensities to source spectrum
	      and surface reflectance
	    </P>
	  </td>
	</tr>
      </table>
    </P>    
    <HR>
      <P>
	<a href="http://en.wikipedia.org/wiki/Inverse_problem"
	   target=new>Inverse problems</a> are typically
	<a href="http://en.wikipedia.org/wiki/Ill-posed_problem"
	   target=new>ill-posed</a> — for instance, their 
	solution may be under-determined by the data, requiring additional
	assumptions (recall <a href="wk-3-2.html" target=n>Lecture 3.2</a>).
      </P>

</div>

      

<div  CLASS="slide">
  <h1>forward and inverse problems (cont.)</h1>

    <P>
      Forward or direct problems: from causes to effects.
      <BR>
      Inverse problems: from effects to causes.
    </P>
    <P>
      <table>
	<tr>
	  <th>domain</th><th>forward</th><th>inverse</th>
	</tr>
	<tr>
	  <td>social dynamics</td>
	  <td>
	    <P>
	      <I>money:</I> from the factors that shape the economy to
	      the actual socioeconomic situation (e.g., inequality)
	    </P>
	    <P>
	      <I>social justice:</I> from the factors that shape "law
	      enforcement" policy to actual outcomes  (e.g., police violence)
	    </P>
	  </td>
	  <td>
	    <P>
	      <I>money:</I> from [current / desired socioeconomic situation] to
	      [the factors that shape it / effective interventions
	      for socioeconomic justice]
	    </P>
	    <P>
	      <I>social justice:</I> from [current / desired societal outcomes]
	      to [their determinants / effective actions]
	    </P>
	  </td>
	</tr>
      </table>
    </P>    
    <HR>
      <P>
	<a href="http://en.wikipedia.org/wiki/Inverse_problem"
	   target=new>Inverse problems</a> are typically
	<a href="http://en.wikipedia.org/wiki/Ill-posed_problem"
	   target=new>ill-posed</a> — for instance, their 
	solution may be under-determined by the data, requiring additional
	assumptions (recall <a href="wk-3-2.html" target=n>Lecture 3.2</a>).
      </P>

</div>



<div  CLASS="slide">
  <h1>re: police violence</h1>

  <img src="US-police-budget.jpeg" class="figure-right" height="550">
    <P>
      Source: <a href="https://stephensemler.substack.com/p/world-military-budgets-vs-us-expenditures?s=r"
      target=new><I>World military budgets vs. US 
      expenditures on police</I></a> (Speaking Security Newsletter |
      Advisory Note for Organizers and Candidates, n°78 | 13 April
	2021).
      </P>

</div>


    
<div  CLASS="slide">
  <h1>re: "domestic terrorism"</h1>

  <img src="Brockovich-Ohio-2023.png" width="95%">
    <P>
      Source: <a href="https://news.yahoo.com/ohio-law-enforcement-links-erin-brockovich-to-potential-for-special-interest-terrorism-threat-in-east-palestine-000636477.html"
      target=new><I>Yahoo news</I></a>
    </P>
    <P>
      <small>
	<a href="https://en.wikipedia.org/wiki/Erin_Brockovich"
	target=new>Erin Brockovich</a> is an American consumer
	advocate and environmental activist who was instrumental in
	building a case against Pacific Gas & Electric Company (PG&E)
	involving groundwater contamination in Hinkley, California in
	1993. Her successful lawsuit was the subject of the
	Oscar-winning film, Erin Brockovich (2000)."
      </small>
    </P>

</div>


    
<div  CLASS="slide">
  <h1>[deep breath]</h1>


</div>

    

<div  CLASS="slide">
  <h1>back to motor control: one-shot vs. incremental</h1>

  <video src="Airplane-drinking&#32;problem.mp4" controls
	 title="Airplane! drinking problem"
	 class="figure-right">
    </video>
  <P>
    In general, motor control involves planning the desired movement
    and coordinating the forces needed to execute it — typically
    INCREMENTALLY and subject to ON-THE-FLY CORRECTIONS.
  </P>

</div>

  

<div  CLASS="slide">
  <h1>motor control: embodiment and situatedness</h1>

  <P>
    Key constraints that apply to the problem of motor control stem
    from the principles of <a
			     href="http://en.wikipedia.org/wiki/Embodied_cognition" target=new>embodiment</a> and <a
														    href="http://en.wikipedia.org/wiki/Situated_cognition" target=new>situatedness</a>.
  </P>
  <P>
  <table cellspacing=10>
    <tr>
      <td>
	<a href="https://en.wikipedia.org/wiki/John_Carter_(film)"
	target=new>John Carter</a> of Virginia discovers that he needs
	to recalibrate. 
      </td>
      <td align=center>
	<video src="JohnCarter-jump.mp4" controls="controls"
	       height=270 width=608>
	</video>
      </td>
    </tr>
  </table>
</div>




<div  CLASS="slide">
  <h1>motor control: embodiment and situatedness</h1>

  <P>
    Key constraints that apply to the problem of motor control stem
    from the principles of <a
			     href="http://en.wikipedia.org/wiki/Embodied_cognition" target=new>embodiment</a> and <a
														    href="http://en.wikipedia.org/wiki/Situated_cognition" target=new>situatedness</a>.
    <table cellspacing=10>
      <tr>
	<td>
	  The octopus <I>O. aculeatus</I> maintains its algae-like
	  camouflage while walking backwards on two arms, using the outer part
	  of each arm like a conveyor belt (video by Crissy Huffard/UC Berkeley).
	</td>
	<td align=center>
	  <video src="octopus-walk.mov" height=446 width=540 controls="controls"
		 align=center>
	  </video>
	</td>
      </tr>
    </table>
  </P>

</div>




<div  CLASS="slide">
  <h1>motor control: agonist/antagonist</h1>

  <img src="arm-muscles.gif" class="figure-right">
  <P>
    Key constraints that apply to the problem of motor control stem
    from the principles of <a
			     href="http://en.wikipedia.org/wiki/Embodied_cognition" target=new>embodiment</a> and <a
														    href="http://en.wikipedia.org/wiki/Situated_cognition" target=new>situatedness</a>.
  </P>
  <P>
    Although some of the information relied upon by the motor system
    (especially for locomotion, orientation and reproduction) is innate, 
    individuals must LEARN — acquire and store <I>motor memories</I> — during their 
    lifetimes.
  </P>
  <P>
    In <a href="https://en.wikipedia.org/wiki/Vertebrate"
	  target=new>vertebrates</a>, many of these take the form of activation values for
    <I>agonist-antagonist</I> muscle pairs, as illustrated here for the case
    of arm control.
  </P>

</div>



<div  CLASS="slide">
  <h1>motor control as equilibrium trajectory shaping (Shadmehr)</h1>

  <img src="Shadmehr-stiffness-2.jpg" class="figure-right">
  <img src="Shadmehr-stiffness-1.jpg">
  <P>
    Arm position, represented here by the shoulder and elbow angles,
    \(q_1\) and \(q_2\), can be controlled by setting the
    <I>equilibrium</I> point of the arm musculature. (Note the
    conceptual parallels to MEMORY.)
  </P>
  <P>
    <I>Left:</I>
    the restoring force generated by a subject's arm can be measured by
    a robotic manipulator that attempts to displace it from the
    equilibrium position. <I>Center and right:</I> Maps showing the
    force fields generated by the arm in the two configurations
    indicated in the left panel.
  </P>

</div>
  



<div  CLASS="slide">
  <h1>reality check: the agonist-antagonist picture is overly simple</h1>

  <img src="finger-control-muscles.jpg" class="figure-right">
  <P>
    On the right: finger control.
  </P>
  <P>
    <font color=gray>[The <a
	  href="http://hospitalforspecialsurgery.interactive.understand.com/view/shoulder/clavicle-fracture"
	  target=new>shoulder complex</a> is a design/control mess, too.]</font>
  </P>
  <HR>
  <P>
    What about learning?
    <DIR>
      "It takes a human being about 14 thousand brain-hours to learn to
      run. An AI can learn to do it in less than half as many CPU-hours, but
      the results are
      <a href="https://twitter.com/eron_gj/status/967672260147470336"
	 target=new>like this</a>."
    </DIR>
  </P>

</div>


<div  CLASS="slide">
  <h1>the overarching problem in control</h1>

  <P>
    Consider the problems that are the staple of psychology textbooks, such as:
    <ul>
      <li>(under "perception") object recognition, etc.</li>
      <li>(under "memory") storage, retrieval, etc.</li>
      <li>(under "attention") focusing, steering, etc.</li>
    </ul>
  </P>
  <P>
    Who orchestrates the processes that solve these problems?
  </P>
  <P>
    Allegedly, the so-called <a
			       href="https://books.google.com/books?id=l8j_z5-qZfAC&pg=PA300&lpg=PA300&dq=%22central+executive%22+psychology&source=bl&ots=iDs4z2yE__&sig=saPBzHTKej4J6_AoXTF3ZW47isQ&hl=en&sa=X&ved=0ahUKEwijua6a58zKAhXJGj4KHbZDAEYQ6AEIZjAL#v=onepage&q=%22central%20executive%22%20psychology&f=false"
			       target=new>"central executive"</a>.
  </P>
  <P class="incremental">
    Having a "central executive" seems to be the only possible
    solution to the ultimate challenge in behavior — DECIDING WHAT TO
    DO NEXT. 
  </P>
  
</DIV>


<div  CLASS="slide">
  <h1>the "central executive" and the homunculus fallacy</h1>

  <video src="homunculus-MiB-2.mov" height=496 width=640
         controls="controls" class="figure-right" >
  </video>
  <img src="homunculus2.jpg" class="figure-right" height=300> 
<!--  <img src="homunculus-MiB.jpg" class="figure-left" height=400> -->
  <P>
    The central executive / homunculus "explanation" invites
    an <a href="http://en.wikipedia.org/wiki/Infinite_regress"
	  target=new>infinite regress</a>, so this
    cannot be how decisions are made, motor or others.
  </P>
  <P class="incremental">
    A better [mechanism-level] explanation: the multiple computational
    processes that constitute a mind interact dynamically; decisions,
    along with the other aspects of behavior, emerge from
    these interactions incrementally, over time.
  </P>
  
</DIV>



<div  CLASS="slide">
  <h1>motor control: distributed, hierarchical decision making</h1>

  <img src="rat-decision-making.jpg" class="figure-right" height=250>
  <P>
    Behavior doesn't just "happen": EACH motor act is the result of a DECISION on
    the part of the animal.
  </P>
  <P class="incremental">
    Decision making is HIERARCHICAL: typically, only the most abstract
    (high-level) decisions are
    explicit<sup><font color=red>*</font></sup> (and perhaps
    conscious); most are not. 
  </P>
  <HR>
    <P class="incremental">
      <sup><font color=red>*</font></sup>Re "explicit": think of
      knocking a glass off the table with your elbow while reaching
      for salt. The decision to reach is explicit; the side effect is
      not — the extremal position of your elbow was never explicitly
      computed by the brain (it was implicitly computed by the body).
    </P>
  <video src="Clumsy.mp4" class="figure-left"
	 width=30%
	 controls=true title="clumsy">
  </video>

</div>



<div  CLASS="slide">
  <h1>motor control and hierarchical decision making</h1>

  <video src="Boston-Dynamics-robodog.mp4" class="figure-right"
	 width=75%
	 controls=true title="Spot by Boston Dynamics">
  </video>
  <P>
    Hierarchical decision making in 
    <a href="https://www.youtube.com/watch?v=wXxrmussq4E"
    target=new>these robots</a> is most probably carried out by
    humans.
  </P>
  <P class="incremental">
    [<a href="https://www.reddit.com/r/SocialistRA/comments/lsnzkd/how_to_disable_police_robot_spot_boston_dynamics/"
    target=new>Safety override</a> for Spot]
  </P>

</div>



  
<div CLASS="slide">
  <h1>[problem- and algorithm-level] decision theory (Körding & Wolpert)</h1>

  <img src="in-astronaut-suit.jpg" class="figure-right" height=200>
  <P>
    <B>Decision theory</B> quantifies how people [and other animals] should choose in the context
    of a given <a href="http://en.wikipedia.org/wiki/Utility"
		  target=new>utility</a> function and some partial knowledge of the world. 
    The expected utility of an action is defined as:
    $$
    E\left[Utility\right] = \sum_{possible~outcomes} p\left(outcome \mid
    action\right)U\left(outcome\right)
    $$
    where \(p(outcome\mid action)\) is the probability of an outcome given an 
    action and \(U(outcome)\) is the utility associated with this
    outcome.
  </P>
  <P>
  <small>
    According to DECISION THEORY people choose the action so as to
    maximize the expected value of utility. Choosing according to this
    criterion is the definition of choosing rationally. Within the
    framework of ECONOMICS, numerous problems have been described in
    these terms. For example, people's decision about the ratio of
    risky to non-risky assets in their <B>portfolio</B> has been
    described in terms of people having partial knowledge about their
    future earnings while maximizing their future utility. Companies'
    decisions about
    <B>wages</B> and employment of workers have been modelled in terms
    of the company having partial information about workers' ability
    and maximizing <B>profits</B>. The decisions of the central bank
    to increase or decrease <B>interest rates</B> have been modelled
    in terms of optimally reducing the uncertainty about future
    inflation.
  </small>
  </P>
  
</div>



<div CLASS="slide">
  <h1>[CLIMATE] "no action" ≠ preserving the status quo</h1>

  <img src="no-action-IPCC-Temperature.gif" class="figure-right" height=70%>
  <P>
    If no action is taken towards CO<sub>2</sub> emission reduction,
    projected temperature rise in 2100 is <B>1.4 degC</B> at a
    minimum, and <B>5.8 degC</B> at a maximum.
  </P>
  <P>
    Source:
    <a href="https://www.ipcc.ch/site/assets/uploads/2018/05/SYR_TAR_full_report.pdf"
    target=new>The Third Assessment Report</a> (2018) by
    Intergovernmental Panel on Climate Change (IPCC).
  </P>

</div>
  
  

<div CLASS="slide">
  <h1>[BACK TO] decision theory (Körding & Wolpert, 2006)</h1>

  <P>
    <B>Decision theory</B> quantifies how people should choose in the context
    of a given <a href="http://en.wikipedia.org/wiki/Utility"
		  target=new>utility</a> function and some partial knowledge of the world.
    The expected utility of an action is defined as:
    $$
    E\left[Utility\right] = \sum_{possible~outcomes} p\left(outcome \mid
    action\right)U\left(outcome\right)
    $$
    where \(p(outcome\mid action)\) is the probability of an outcome given an 
    action and \(U(outcome)\) is the utility associated with this
    outcome.
  </P>
  <P>
    <B>Economics</B> tries to understand both how agents should optimally
    behave when deciding under uncertainty and how they actually
    behave in such cases. Bayesian decision making is the systematic
    way of combining Bayesian estimates of probability with
    utility functions.
  </P>
  <P>
    <font color=red><B>Optimal control</B> aims to solve similar problems where the decision
      is not just happening at one point of time but a continuous output
      (such as muscle force).</font> <B>The expected utility changes constantly</B>
    according to new information coming in. Solutions to this problem
    typically use the notion of 'cost-to-go': the average integrated cost from
    a current state to a target state.
  </P>

</div>



<div CLASS="slide">
  <h1>estimating utility functions through psychophysical experimentation (Körding & Wolpert, 2006)</h1>

  <img src="Koerding-TICS06-fig2.png" class="figure-right" height=250>
  <P>
    <B>(a)</B> Indifference (constant-cost) curves in the force–time
    space as predicted by different cost (utility) functions. The cost
    is the same along each curve.
  </P>
  <P>
    <B>(b)</B> The cost is inferred from the subject's decisions. The "hotter"
    the colour, the less desirable the force.
  </P>
  <P>
    <font color=gray>
      <small>
	Human volunteers had to produce forces of varying
	magnitude and duration. During each trial subjects
	had to choose which of two combinations of force
	magnitude and duration they prefer. From a large number
	of such choices it is possible to infer the indifference lines
	in the F–T space. From these indifference
	curves it is possible to infer the cost function.
      </small>
    </font>
  </P>

</div>
  
  

<div CLASS="slide">
  <h1>a refresher: Bayesian integration of priors with observations (Körding & Wolpert, 2006)</h1>

  <img src="Koerding-TiCS06-figI.png" class="figure-right">
  <P>
    \(\require{color}\)
    When we have a Gaussian prior distribution \(p\left(x\right)\) and we have a noisy
    observation \(o\) of the position that leads to a Gaussian likelihood
    \(p\left(o\mid x\right)\), it is possible to use Bayes rule to 
    calculate the posterior distribution (how probable
    is each value given both the observation and the prior knowledge):
    $$
    p\left(x\mid o\right) = \frac{p\left(o\mid x\right) p(x)}{p(o)}
    $$
    This equation assigns a probability to every possible value. If we
    assume that the prior distribution \(p\left(x\right)\) is a 
    Gaussian with variance \(\sigma^2_p\) and mean \({\color{green}\mu}\) [<font color=green>green</font>]
    and that the likelihood \(p\left(o\mid x\right)\) is
    also a Gaussian with variance \(\sigma^2_o\) and mean \({\color{red}o}\) [<font
										color=red>red</font>], it is 
    possible to compute analytically the posterior, which is then also
    Gaussian [<font color=orange>yellow</font>]. <strike>The</strike> An optimal estimate
    \(\hat{x}\) that is the maximum of the 
    posterior is \(\hat{x} = \alpha {\color{red}o} + \left(1 - \alpha\right){\color{green}\mu}\),
    where \(\alpha = \frac{\sigma^2_p}{\sigma^2_p + \sigma^2_o} \le 1\).
    Moreover the width of the posterior is \(\sigma^2 =
    \alpha\sigma_o\).
  </P>

</div>



  <div CLASS="slide">
  <h1>Bayesian integration in a perceptual-motor task (Körding & Wolpert, 2006)</h1>

  <img src="Koerding-TiCS06-Bayesian-motor-control.png" height=500 class="figure-right">
  <P>
    (a) Perception and movement are beset by uncertainty. <small>When we briefly look at
      our hand we cannot be certain where exactly it is. The resulting
      uncertainty is sketched as the grey probability distribution around the 
      finger at upper left. When we only feel our hand without looking we might have
      more uncertainty (below). Right: if we make a fast movement from a starting
      position to a target we will not always hit the target (<font color=red>X</font>) but there will be some
      probability distribution of endpoint position.</small>
  </P>
  <P>
    (b) Example: The other player is hitting the ball. Seeing the ball, we can
    estimate that it will land in the red region. We have a prior belief that
    the ball will land in the green region. The black ellipses denote the
    posterior, the region where the Bayesian estimate would predict the ball
    to land.
  </P>
  <P>
    (c) The experimental set-up in typical movement psychophysics
    experiments.
  </P>
  <P>
    (d) Human subjects' reliance on the prior as a function of increasing
    perceptual uncertainty. (From the previous slide, <B>the larger the
    likelihood noise \(\sigma_o\), the larger the weight of the prior
    mean \(\mu\) in the posterior maximum \(\hat{x}\).</B>)
  </P>
  <P>
    (e) The prior inferred from subject behavior, for the different
    conditions and subjects. The actual distribution used in the
    experiment is shown in red.
  </P>

</div>

  

<div CLASS="slide">
  <h1>the (Bayesian) motor control loop (Körding & Wolpert, 2006)</h1>

  <img src="Koerding-TiCS06-fig3.png" class="figure-right">
  <P>
    In generating a movement, the controller, an optimal decision maker, takes
    into account both the output of the Bayesian estimation process and
    the utility function (which typically CHANGES over time).
  </P>
  <P>
    The Bayesian estimator combines:
    <ol>
      <li>inputs from the sensors (for example, about limb positions);</li>
      <li>prior knowledge;</li>
      <li>the <a href="http://en.wikipedia.org/wiki/Efference_copy"
		 target=new>efference copy</a> (a copy of the signal sent by the central
	nervous system to the muscles).</li> 
    </ol>
    This Bayesian approach leads to a better estimate of possible outcomes than any
    estimate that is only based on the sensory input.
  </P>

</div>




<div  CLASS="slide">
  <h1>[EXTRA] a reality check: some major components of the behavioral control system</h1>

  <img src="Wise-Shadmehr-02-fig1.png" title="motor control"
  class="figure-right">
  <P>
    Speaking of control loops: a bit of perspective on the brain...
  </P>
  <P>
    <font color=gray>
      Gray arrows: <a href="http://en.wikipedia.org/wiki/Cerebral_cortex" target=new>cortico</a>fugal projections; open arrows and arrowheads: projections to
      effectors; gray box: the <a
				 href="http://en.wikipedia.org/wiki/Basal_ganglia" target=new>basal
	ganglia</a>; stippled ovals: preganglionic 
      autonomic motor nuclei. GPi, internal segment of <a
							 href="http://en.wikipedia.org/wiki/Globus_pallidus" target=new>globus pallidus</a>; GPe, 
      external segment of <a href="http://en.wikipedia.org/wiki/Globus_pallidus"
			     target=new>globus pallidus</a>; STN, sub<a
								       href="http://en.wikipedia.org/wiki/Thalamus" target=new>thalamic</a> nucleus; SNr,
      <a href="http://en.wikipedia.org/wiki/Substantia_nigra"
	 target=new>substantia nigra</a> pars reticulata. 
      <BR>
	<small>[<I>Motor Control</I>, 
	  Steven P. Wise and Reza Shadmehr, Encyclopedia of the Human Brain, vol.3
	  (2002)]</small>
      </font>
  </P>
  <HR>
  
</div>


<DIV CLASS="slide">
  <h1>EXTRA for neurobio students: brain basis of ON-THE-FLY perception/action (after Sherman and Guillery, 2006)</h1>

  <img src="Sherman06-fig10.1.png" height=550 class="figure-right">
    <P>
      "Schematic, and simplified, representation of
      <a href="https://en.wikipedia.org/wiki/Thalamus"
	 target=new>thalamic</a> and 
      <a href="https://en.wikipedia.org/wiki/Cerebral_cortex" target=new>cortical</a> connections 
      with motor centers.
      <small>
	<BR><B>A</B>. A widely
	  used representation of
	  <a href="https://en.wikipedia.org/wiki/Afferent_nerve_fiber"
	     target=new>afferent</a> pathways entering through thalamus being 
	  processed through a parallel and hierarchical series of cortical connections, and
	  then passed on to motor centers or memory
	  storage. <font color="gray">[Consider <a href="thalamus-and-cortex.jpg"
						   target=pic>this
	      example</a> from some online course or other.]</font>
	  <BR><B>B</B>. A representation of the connections described in
	    earlier chapters and in this chapter, showing first order (FO)
	    and higher order (HO) thalamic relays receiving from ascending
	    and corticothalamic afferents, respectively, with each of these
	    afferents sending axonal branches to motor or premotor centers. 
	    <BR><B>C</B>. A schema to stress that essentially all
	      cortical areas have connections to motor or premotor centers. The extent to
	      which they have branches going to the thalamus remains largely
	      unexplored."
	    </small>
	    </P>
      <HR>
	<P>
	  "Not only CAN `motor assembly begin before sensory signals reach
	  the highest levels' but that it MUST begin before the
	  sensory signals even reach the thalamus, and that it must
	  accompany corticocortical processing at essentially every
	  stage."
	  <BR>
	    — S. M. Sherman and R. W. Guillery
	    (2006). <a href="https://mitpress.mit.edu/books/exploring-thalamus-and-its-role-cortical-function"
	    target=new><I>Exploring the 
	    Thalamus and Its Role in Cortical Function</I></a>, MIT
	    Press, p.362.
	  </P>

</div>


<DIV CLASS="slide">
  <h1>EXTRA: brain basis of ON-THE-FLY perception/action (after Sherman and Guillery, 2006)</h1>

  <img src="Sherman06-fig10.4.png" height=450 class="figure-right">
    <P>
      <small>
      <B>A</B>. Direct
      <a href="https://en.wikipedia.org/wiki/Lemniscus_(anatomy)"
      target=new>lemniscal</a> (continuous lines) and
      <a href="https://en.wikipedia.org/wiki/Anterior_spinothalamic_tract"
      target=new>anterolateral</a> 
      (interrupted lines) pathways to the thalamus.
      <BR>
	<B>B</B>. Additional connections
	established by branches of the direct pathways.
	<P>
	  </small>
	  <HR>
    <P>
      "Each axon reaching the thalamus
      will carry messages about the condition of one or several receptors and
      in addition will carry information about the instructions that are already
      on their way to one or more motor pathways. One should not expect
      that the cortical analysis will reject or annul this “additional” information
      simply because it is not a part of what classical physiology has seen
      as the information carried in sensory pathways. It is reasonable to expect
      this copy of motor instructions to be an integral part of the perceptual
      process."
	  <BR>
	  — S. M. Sherman and R. W. Guillery
	    (2006). <a href="https://mitpress.mit.edu/books/exploring-thalamus-and-its-role-cortical-function" target=new><I>Exploring
	    the
	    Thalamus and Its Role in Cortical Function</I></a>, MIT
	    Press, p.367.

</div>



  
<div class="footer">
<p>Last modified: Tue Feb 27 2024 at 15:51:51 EST</p>
</div>
</body>
</html>
