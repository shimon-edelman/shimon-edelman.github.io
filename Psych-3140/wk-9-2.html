<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 w-9-2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2014-2024 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 9.2 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych 3140/6140</h1>
    <p>Computing the Mind</p>
  </div>
  <div style="float:left">
    <h2>Week 9: higher cognition, II</h2>
    <h3>&nbsp;Lecture 9.2: induction</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->





<DIV CLASS="slide">
  <h1>the agenda</h1>

  <img src="mushrooms.jpg" class="figure-right" height=70%>
  <P>
<!--  <img src="swans.jpg" class="figure-right" height=250> -->
  <ul>
    <li>
    the Induction Problem, and a <B>very general</B> Bayesian approach:
    <ul>
      <li>
      How does abstract knowledge guide learning and reasoning from sparse
      data?
      </li>
      <li>
      What forms does our knowledge take, across different domains and
      tasks?
      </li>
      <li>
      How is that abstract knowledge itself acquired?
      </li>
    </ul>
    </P>

</div>



<DIV CLASS="slide">
  <h1>INDUCTION: reasoned knowledge from evidence</h1>

  <img src="Peirce-beans.jpg" class="figure-right" height=50%>
  <P>
    Modes of reasoning (compare with
    <a href="wk-9-1.html#(14)"
       target=new>slides #14-#19 of Lecture 9.1</a>) —
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/Deductive_reasoning"
      target=new>deduction</a>: from premises to consequences [logical]</li>
      <li><a href="https://en.wikipedia.org/wiki/Abductive_reasoning"
      target=new>abduction</a>: from a single case to a likely
      explanation (which cause/rule is responsible for this case?) [statistical]</li> 
      <li><a href="https://en.wikipedia.org/wiki/Inductive_reasoning"
      target=new><B>induction</B></a>: from multiple cases to a
      general rule (what rule can unify all these cases?) [statistical]</li> 
    </ul>
  </P>
  <img src="bean-bag.png" height=30%>
  
</div>

  


<DIV CLASS="slide">
  <h1>a reminder from Lecture 4.2 (generalization): Bayesian induction in the "numbers game" (Tenenbaum, 1999)</h1>
  
  <img src="Tenenbaum99-fig1.jpg" class="figure-right" height=75%>
    <font color=gray>
      <P>
	Class I trials &#151; the exemplar set consists of one number from
	each concept.
      </P>
      <P>
	Class II trials  &#151; four numbers, consistent with a simple rule.
      </P>
      <P>
	Class III trials  &#151; four random numbers of similar magnitude.
      </P>
    </font>
  <P>
    Two groups of hypotheses used: (1) salient
    mathematical properties: odd, even, square, cube, and prime
    numbers, multiples and powers of small numbers, and sets of
    numbers ending in the same digit; (2) all intervals of consecutive
    numbers with endpoints between 1 and 100.
  </P>
  
</div>




<DIV CLASS="slide">
  <h1>a Bayesian model of category induction (Sanjana & Tenenbaum, 2002)</h1>

  <img src="Tenenbaum02-fig3.jpg" class="figure-right" height=85%>
  <P>
    (given) Chimps are susceptible to the disease blicketitis.<BR>
      (given) Squirrels are susceptible to the disease blicketitis.<BR>
	<HR width=30% align=left>
	  <P>
	    (true or false?) Horses are susceptible to the disease blicketitis.
	  </P>
  <HR>
    <img src="Tenenbaum02-fig1.jpg" height=50% class="figure-right">
  <P>
    <I>Right:</I> the assumed representation of the structure of
    similarities among animals, based on similarity judgments made by
    subjects in a separate norming study. This is the basis for the
    HYPOTHESIS SPACE of the Bayesian model.
  </P>
  
</div>



<DIV CLASS="slide">
  <h1>a Bayesian model of category induction (Sanjana & Tenenbaum, 2002)</h1>

  <img src="SanjanaTenenbaum02-fig3.jpg" height=70%>
    <P>
      Correlations between the generalization scores of three models
      and of the human subjects, in three versions of the induction
      task (<I>n</I> indicates the number of premise examples).
    </P>
  
</div>



  
<DIV CLASS="slide">
  <h1>main characteristics of induction in humans: note the role of STATISTICS</h1>

  <I>Inferences from single cases:</I>
  <DIR>
    1. <SC>Similarity</SC> between premise and conclusion categories promotes
    induction.
    <BR>
    2. <SC>Typicality</SC> of the premise category promotes induction.
    <BR>
    3. <SC>Homogeneity</SC> of the conclusion category promotes induction.
  </DIR>
  <I>Inferences from multiple cases:</I>
  <DIR>
    4. Greater <SC>number</SC> of observations, or premises, promotes induction.
    <BR>
    5. Greater <SC>diversity</SC> of observations, or premises, promotes induction.
  </DIR>
  <I>Influence of properties (<SC>context</SC>):</I>
  <DIR>
    6. People draw inferences differently depending on the property being
    projected.
    <BR>
    7. Some properties are idiosyncratic or transient, with a
    narrow scope for inferences, whereas other properties are more
    broadly projected.
    <BR>
    8. The assessment of similarity between categories in an
    argument depends on the property being projected (cf. the "ball, moon,
    candle" example).
  </DIR>

</div>




<DIV CLASS="slide">
  <h1>induction: going from episodic [memory] data to conceptual knowledge</h1>

  <img src="Tenenbaum-Science11-fig1a.png" class="figure-right" height=80%>
  <P>
    Children learning names for object concepts routinely make strong
    generalizations from just a few examples. The same processes of rapid
    generalization can be studied in adults learning names for novel objects
    created with computer graphics.
  </P>
  <P>
    Here, given these alien objects and three examples (boxed in <font
								   color=red>red</font>) of "tufas" (a word in the alien language), which
    other objects are tufas? Almost everyone selects just the objects boxed in
    gray.
  </P>
  <P>
  <small>
    <I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
    J. B. Tenenbaum et al., Science 331:1279 (2011).
  </small>
  </P>

</div>
  


<DIV CLASS="slide">
  <h1>a reminder: weighing statistical evidence using Bayes</h1>

  <img src="Tenenbaum-Science11-Bayes.png" height=20%>
<!--  <img src="Bayes-1.jpg">  <img src="Bayes-2.jpg">  -->
  <P>
    <I>d</I> &#151; the observed data;
    <BR>
      <I>h</I> &#151; the hypothesis in question;
      <BR>
	<I>H</I> &#151; the space of all possible hypotheses (which may be
	<B>intricately structured</B>).	
  </P>
    <HR>
      <P>
	<small>
	  <I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
	  J. B. Tenenbaum et al., Science 331:1279 (2011).
	</small>
      </P>

</div>



<DIV CLASS="slide">
  <h1>A GENERAL FRAMEWORK FOR INDUCTION: structured statistics (Tenenbaum et al., 2011)</h1>

  <img src="Tenenbaum-Science11-fig1b.png" class="figure-right" height=70%>
  <P>
    Learning names for categories can be modeled as Bayesian inference over a
    tree-structured domain representation. <small>Objects are placed at the leaves
      of the tree; hypotheses about categories that words could label
      correspond to different nodes. Nodes at different depths pick out
      hypotheses at different levels of generality (e.g.,
    <a href="https://en.wikipedia.org/wiki/Clydesdale_horse"
      target=new>Clydesdales</a>, draft horses, horses, animals, or
      living things).</small>
  </P>
  <P>
    <I>Priors</I> [on category labels] favor higher-placed nodes and
    coherent categories.
  </P>
  <P>
    <I>Likelihoods</I> [of images, given labels] assume that examples are
    drawn randomly from the node labeled by the word, favoring lower
    nodes that cover the examples tightly. (This captures the sense of
    <a href="Bayesian-suspicious-coincidences.html"
       target=new><I><B>suspicious coincidence</B></I></a>: it would be
    very improbable — suspicious — for all examples of a
    word to cluster under the same lower branch of the tree if the word
    actually labels a high node.)
  </P>
  <P>
    <I>Posterior probabilities</I> [of labels, given images] are computed by
    combining priors and likelihoods. The results favor generalizing across the
    lowest distinctive branch that spans all the observed examples (boxed in
    gray).
  </P>

</div>
  



<DIV CLASS="slide">
  <img src="Tenenbaum-Science11-fig2a.png" class="figure-right" height=90%>
  <h1>induction as STRUCTURED statistics</h1>

  <P>
    A search algorithm attempts to find both the form \(F\) (dictated by the
    abstract principles) and the structure \(S\) of that form that jointly
    maximize  \(P(S,F\mid D)\), the posterior probability of the structure and
    form, given data \(D\). That posterior is a function of the product of \(P(D\mid
    S)\) and \(P(S\mid F)\).
  </P>
  <P>
    In this example, the algorithm is given as data the features of animals;
    it then  finds a tree structure with intuitively sensible categories at 
    multiple scales.
  </P>
  <P>
    [For examples of structures other than trees, see the next slide.]
  </P>
  <HR>
    <P>
      <small>
	<I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
	J. B. Tenenbaum et al., Science 331:1279 (2011).
      </small>
    </P>

</div>



<DIV CLASS="slide">
  <img src="Tenenbaum-Science11-fig2.png" class="figure-right" height=90%>
  <h1>induction as STRUCTURED statistics</h1>

  <P>
    A search algorithm attempts to find both the form \(F\) (dictated by the
    abstract principles) and the structure \(S\) of that form that jointly
    maximize \(P(S,F\mid D)\), the posterior probability of the structure and
    form, given data \(D\). That posterior is a function of the product of
    \(P(D\mid S)\) and \(P(S\mid F)\). 
  </P>
  <P>
    <table align=center>
    <tr><td></td><td><I>problem setting</I></td><td><I>form</I></td></tr>
    <tr><td>(A)</td><td>animal species taxonomy</td><td>tree</td></tr>
    <tr><td>(B)</td><td>SCOTUS conservative/liberal</td><td>chain</td></tr>
    <tr><td>(C)</td><td>color similarity</td><td>ring</td></tr>
    <tr><td>(D)</td><td>latitude/longitude</td><td>ring \(\times\) chain</td></tr>
    <tr><td>(E)</td><td>morphed face images, 2 parameters</td><td>chain \(\times\) chain</td> </tr>
    </table>
  </P>
  <HR>
    <P>
      <small>
	<I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
	J. B. Tenenbaum et al., Science 331:1279 (2011).
      </small>
    </P>

</div>



<DIV CLASS="slide">
  <img src="Tenenbaum-Science11-fig3ab.png" class="figure-right" height=90%>
  <h1>CAUSAL induction — hierarchical Bayesian models</h1>

    <P>
      Hierarchical Bayesian Models defined over graph schemas can
      explain how intuitive theories are acquired and used to learn
      about specific causal relations from limited data.
    </P>
    <P>
      (<B>A</B>) A medical reasoning domain described by relations
      among 16 variables: “diseases” (top row), with causal links to
      “symptoms” (bottom row). This network can also be visualized as
      a matrix (top right, links shown in black). The causal learning
      task is to reconstruct this network based on observing data on
      the states of these 16 variables in a set of patients.
    </P>
    <P>
      (<B>B</B>) A two-level HBM formalizes bottom-up causal learning
      or learning with an uninformative prior on networks. <small>The
      bottom level is the data matrix D. The second level (structure)
      encodes hypothesized causal networks: a grayscale matrix
      visualizes the posterior probability that each pairwise causal
      link exists, conditioned on observing n patients; compare this
      with the ground truth in (A). The true causal network can be
      recovered perfectly only from observing very many patients (n =
      1000; not shown). With n = 80, spurious links (gray squares) are
      inferred, and with n = 20 almost none of the true structure is
      detected.</small>
    </P>    
    <HR>
      <P>
	<small>
	  <I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
	  J. B. Tenenbaum et al., Science 331:1279 (2011).
	</small>
      </P>
    
</div>

    

<DIV CLASS="slide">
  <img src="Tenenbaum-Science11-fig3d.png" class="figure-right" height=90%>
  <h1>causal induction — hierarchically STRUCTURED statistics</h1>

  <P>
    A Hierarchical Bayesian model for learning an abstract theory of
    causality.
  </P>
  <P>
    At the highest level are laws expressed in first-order logic
    representing the abstract properties of causal relationships, the
    role of exogenous interventions in defining the direction of
    causality, and features that may mark an event as an exogenous
    intervention. <font color=gray>[The logical formulas in this
    example are meaningless and serve illustration purposes
    only.]</font>
  </P>
  <P>
    These laws place constraints on possible directed graphical models
    at the level below, which in turn are used to explain patterns of
    observed events over variables.
  </P>
  <P>
    Given observed events from several
    different causal systems, each encoded in a distinct data matrix,
    and a hypothesis space of possible laws at the highest level, the
    model converges quickly on a correct theory of intervention-based
    causality and uses that theory to constrain inferences about the
    specific causal networks underlying the different systems at the
    level below.
  </P>
  <HR>
    <P>
      <small>
	<I>How to Grow a Mind: Statistics, Structure, and Abstraction</I>,
	J. B. Tenenbaum et al., Science 331:1279 (2011).
      </small>
    </P>

</div>
    


<DIV CLASS="slide">
  <h1>NEXT TOPIC: higher cognition III: general intelligence</h1>

  <img src="animal-IQ-test.jpg" class="figure-right" height=65%>
  <P>
    General intelligence
    <ul>
      <li>
	<B>in nonhuman animals</B>
      </li>
      <li>
	in humans (IQ / gF)
      </li>
    </ul>
  </P>
  <P class="incremental">
    "In animals, intelligence is thought to involve an individual’s
    ability to acquire new knowledge from interactions with the
    physical or social environment, use this knowledge to organize
    effective behavior in both familiar and novel contexts, and engage
    with and solve novel problems."
  </P>

</div>  



<DIV CLASS="slide">
  <h1>prefrontal cortex (PFC) size and gF in non-human species</h1>

  <img src="mouse_monkey_human.jpg" height=65% class="figure-right"
  title="prefrontal cortex in mouse, monkey, human">
  <P>
    Respect the mouse!
  </P>
  <HR>
  <P>
  "Recent studies are consistent with the presence of general intelligence in mammals
  (rodents and primates)."
  <DIR><DIR><DIR>
	—
	<a href="https://www.aim.uzh.ch/de/members/professors/judithburkart.html"
	target=new>Judith M. Burkart</a> et
	al. (2018). <a href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/the-evolution-of-general-intelligence/5AB1923F6D39AEED6AFB91E5AACCEE8E" target=new><I>The
	evolution of general intelligence</I></></a>. Behavioral and Brain
	Sciences 40:e195. 
  </DIR></DIR></DIR>
  </P>
  
</div>


<DIV CLASS="slide">
  <h1>from Burkart et al. (2017)</h1>

  <img src="Burkart17-tab1.png" height=80% class="figure-right">
    <P>
      "In animals, intelligence is thought to involve an individual’s
      ability to acquire new knowledge from interactions with the
      physical or social environment, use this knowledge to organize
      effective behavior in both familiar and novel contexts, and ENGAGE
      WITH AND SOLVE NOVEL PROBLEMS."
    </P>
    <HR>
    <P class="incremental">
      general problems <BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &darr;</center><BR>
      general intelligence
    </P>
    
</div>

  

<div class="footer">
<p>Last modified: Wed Mar 20 2024 at 18:38:20 EDT</p>
</div>
</body>
</html>
