<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 w-12-2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2014-2021 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 12.2 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych/Cogst/Info 2140/6140</h1>
    <p><a href="http://kybele.psych.cornell.edu/~edelman">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 12: neurons, II</h2>
    <h3>&nbsp;Lecture 12.2: spike timing</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->




<DIV  CLASS="slide">
  <h1>what neurons do: keep track of, and act upon, precise timing of spikes</h1>

  <!--
  <embed src="brain-scan.mp4" height=256 width=320 controller=true
  autoplay=false align=right hspace=20>
  -->
  <P>
    <ul>
      <li>
	<font color=gray>Timing in COINCIDENCE DETECTION: as in the
	  barn owl sound localization circuit (week 2); also in
	  readout (week 11).</font>
      </li>
      <P>
	<li>
	  Timing in learning: as in Spike Timing-Dependent Plasticity
	  (<a href="http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity"
	      target=new>STDP</a>).
	<ul>
	  <li>
	    Hebb/BCM is a function-level account of learning through
	    synaptic modification;
	  </li>
	  <li>
	    STDP completes the picture by offering a step-by-step
	    analysis and model of the contribution of spiking activity
	    to synaptic modification.
	  </li>
	</ul>
	</li>
      </ul>
    </P>
  
</div>




<DIV  CLASS="slide">
  <h1>learning from experience through synaptic modification</h1>

  <img src="STDP-Fig1.jpg" title="STDP" class="figure-right">
  <P>
    Learning from experience at the level of the synapse:
  </P>
  <P>
    &#151; modification of synaptic
    weight through Spike Timing-Dependent Plasticity
    (<a href="http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity"
	target=new>STDP</a>).
  </P>
  <P>
    \(w_{ij}\): the weight of the synapse between the presynaptic neuron \(j\)
    and the postsynaptic neuron \(i\).
  </P>
  <P>
    \(\frac{\Delta w_{ij}}{w_{ij}}\): normalized change in the value of the
    synaptic weight.
  </P>
  <P>
    The abscissa of the plot shows the time difference between the
    pre- and post-synaptic spikes, \(\Delta t = t_{j}^{pre} -
    t_{i}^{post}\), in milliseconds.  Circles are actual data points
    from a recording, to which a curve was fitted. Note that the curve
    is sharply discontinuous at \(\Delta t = 0\).
  </P>

</DIV>



<DIV  CLASS="slide">
  <h1>molecular basis of STDP (from Natalia Caporale & Yang Dan, 2008)</h1>

  <img src="CaporaleDan08-fig2.png" title="STDP" class="figure-right">
  <P>
    A schematic representation of the molecular signaling pathways
    involved in STDP induction.
  </P>
  <P>
    In LTP induction (right), the NMDA receptors act as coincidence
    detectors for pre- and postsynaptic spiking. In LTD induction
    (left) the coincidence detector may vary across synapses.
  </P>
  <P>
    <font color=gray>
      The diagram includes several pathways that have been suggested
      to play a role in LTD. Red oval indicates possible coincidence
      detectors. Arrow indicates activation/potentiation. Blunt-ended
      line indicates inhibition/suppression. Abbreviations:
      eCB, <a href="https://en.wikipedia.org/wiki/Endocannabinoid_system"
      target=new>endocannabinoids</a>; ER, endoplasmic reticulum; Glu,
      glutamate; IP3, inositol 1,4,5-triphosphate; PLC, phospholipase
      C; VDCCs, voltage-dependent Ca2+ channels.
    </font>
  </P>

</div>





<DIV  CLASS="slide">
  <h1>(a mathematical formalization of) the STDP rule</h1>

  <img src="STDP-fig2.png" height=300 title="STDP"
       class="figure-right">
  <P>
    (If you're unfamiliar with the
    <a href="https://en.wikipedia.org/wiki/Dirac_delta_function"
    target=new>Dirac \(\delta\)</a> notation or with differential
    equations, use the illustration and the boldface text below.)
  </P>
  <small>
  <P>
    Each presynaptic spike arrival leaves a trace \(x_j(t)\) which is updated by an
    amount \(a_{+}(x_j)\) at the moment of spike arrival and decays exponentially in
    the absence of spikes:
    $$
    \tau_{+}\frac{dx_j}{dt} = -x_j + a_{+}(x_j) \sum_f \delta\left(t -
    t_j^f\right)
    $$
    Similarly, each postsynaptic spike leaves a trace \(y\)
    $$
    \tau_{-}\frac{dy}{dt} = -y + a_{-} \sum_n \delta\left(t - t^n\right)
    $$
    which increases by \(a_{−}(y)\) at the moment of postsynaptic
    spikes. The weight change is then
    $$
    \frac{dw_j}{dt} = A_{+}\left(w_j\right) x\left(t\right) \sum_n
    \delta\left(t-t^n\right) - A_{-}\left(w_j\right) y\left(t\right) \sum_f
    \delta\left(t-t_j^f\right)
    $$
  </P>
  </small>
  <P>
    <B>Thus, the weight is (1) increased at the moment of a
    postsynaptic spike by an amount that depends on the value of the
    trace \(x\) left by the presynaptic spike, and (2) decreased at
    the moment of presynaptic spike by an amount proportional to the
    trace \(y\) left by previous postsynaptic spikes.</B>
  </P>

</div>



<DIV  CLASS="slide">
  <h1>STDP and Hebbian learning rules</h1>

  <P>
    STDP can be seen as a spike-based formulation of Hebbian learning:
    in a sense, it is "Hebb, done right".
  </P>
  <P>
    Hebb (1949) proposed that a synapse should be strengthened if a
    presynaptic neuron 'repeatedly or persistently takes part in
    firing' the postsynaptic one. This formulation suggests a
    potential <a href="https://plato.stanford.edu/entries/causation-process/"
    target=new><B>causal</B></a> relation between the firing of the
    two neurons. Causality requires that the presynaptic neuron fires
    slightly before the postsynaptic one. Hebb did not, however,
    postulate the existence of synaptic weakening. The anti-Hebbian
    (weakening) component is found in Oja and BCM rules.
  </P>

</div>



<DIV  CLASS="slide">
  <h1>STDP versus firing rate-based learning rules</h1>

  <P>
    Under the assumption of stationary
    <a href="http://en.wikipedia.org/wiki/Poisson_distribution"
       target=new>Poisson statistics</a> for the firing times of pre-
       and postsynaptic neurons, the most relevant aspect of the STPD
       function from slide 5 is its integral and an STDP model can
       mapped to an equivalent rate-based learning rule.<sup>*</sup>
  </P>
  <P>
    Another point to note: for standard STDP models,
  <!--
  \(\beta>0\) , i.e., presynaptic spike arrival
  leads on average to a positive change  of the synapse, because it is
  likely to cause postsynaptic firing. This is  then often combined with a
  negative integral over the STDP function \(\alpha<0\) , so that
  -->
    random pairings of pre- and postsynaptic firings lead to a weakening
							of the
							synapse.
							</P>
  <HR width=30% align=left>
    <P>
      *<small>
      <font color=gray>
	Assuming independence between pre- and postsynaptic firing,
	  the total weight change is \(\Delta w_{ij} = \alpha f_i(t)
	  f_j(t)\) where \(f_j(t)\) and \(f_i(t)\) denote the firing
	  rate of pre- and postsynaptic neurons averaged over some
	  time \(T\) and \(\alpha = \int W(s)ds\) is the integral over
	  the learning window. If the integral is positive, STDP is
	  identical to standard rate-based Hebbian learning. For
	  negative integral, as often used in modeling, STDP
	  corresponds to a anti-Hebbian rate rule.
	<P>
	  However, the assumption of independence of pre- and
	  postsynaptic firing is obviously wrong: it neglects the
	  causal correlations generated by the interaction of the two
	  neurons. A more precise mapping to rate models can be
	  achieved if the postsynaptic neuron is described as an
	  inhomogeneous Poisson Process with a rate \(f_i(t) = \gamma
	  \sum_j \sum_f \epsilon(t−t^f_j)\) where \(t^f_j\) denotes
	  the spike times of a presynaptic neuron \(j\) generated by a
	  Poisson process of rate \(f_j(t)\) and \(\epsilon(s)\) for
	  \(s>0\) describes the time course of a postsynaptic
	  potential. The total weight change in a period \(T\) is then
	  \(\Delta w_{ij} = \alpha f_i(t)f_j(t) + \beta f_j(t)\) where
	  \(\beta = \gamma \int_{0}^{\infty} \epsilon(s)W(s)ds\) is
	  the integral over the 'causal' part of the learning window,
      i.e., over all times with 'pre-before-post' relation.
  </font></small>

</div>



<DIV  CLASS="slide">
  <h1>time-dependent plasticity and the time scale of reward (Izhikevich, 2007)</h1>

  <P>
    In
    <a href="https://en.wikipedia.org/wiki/Classical_conditioning"
       target=new>Pavlovian or classical</a> and
    <a href="https://en.wikipedia.org/wiki/Operant_conditioning"
       target=new>instrumental or operant</a> conditioning, reward
       typically comes seconds after reward-triggering actions,
       creating the <B>distal reward problem</B> [a.k.a. the Credit
       Assignment Problem from
       <a href="wk-7-2.html#(12)"
       target=lec>Lecture 7.2</a>]: How does the brain
       know what firing patterns of what neurons are responsible for
       the reward if 1) the patterns are no longer there when the
       reward arrives and 2) all neurons and synapses are active
       during the waiting period to the reward?
  </P>
  <P>
    The conundrum can be resolved by combining spike-timing-dependent
       plasticity (STDP) with modulation by
      <a href="https://en.wikipedia.org/wiki/Dopamine"
      target=new>dopamine</a> (DA). Although STDP is triggered by
      nearly coincident firing patterns on a millisecond timescale,
      slow kinetics of subsequent synaptic plasticity is sensitive to
      changes in the extracellular DA concentration during the
      critical period of a few seconds.
  </P>
  <P>
    <small>
      E. Izhikevich (2007). <a href="https://academic.oup.com/cercor/article/17/10/2443/314939" target=new><I>Solving the Distal Reward
	  Problem through Linkage of STDP and Dopamine
	  Signaling</I></a>. Cerebral Cortex  17:2443-2452.
    </small>
  </P>

</div>
  


<DIV  CLASS="slide">
  <h1>time-dependent plasticity and the time scale of reward (Izhikevich, 2007)</h1>

  <img src="Izhikevich07-fig1.png" class="figure-right" height=450>
    <B>Instrumental conditioning of a synapse.</B>
  </P>
  <P>
    (a) The dynamics of each synapse is described by synapse strength
      \(s\) and
      <a href="http://www.scholarpedia.org/article/Temporal_difference_learning#Eligibility_Traces"
	 target=new>eligibility trace</a> \(c\), which are gated by
	 the extracellular DA \(d\). Firings of the pre- and
	 postsynaptic neurons induce changes to the variable \(c\)
	 according to the STDP rule, shown in (b). These changes
	 result in modification of the synaptic strength \(s\) only
	 when extracellular DA is present (\(d>0\)) during the
	 critical window of a few seconds while the eligibility trace
	 c decays to zero.
  </P>
  <P>
    (c) The magnification of the region in (d) marked by *. To
    reinforce coincident firings of 2 coupled neurons, a reward
    (step-increase of variable \(d\)) is delivered with a random delay
    (between 1 and 3 s) each time a postsynaptic firing occurs within
    10 ms after a presynaptic firing (marked by a rectangle in
    (c)). This increases \(c\) more than any random firings of the
    same neurons during the delayed period.
  </P>
  <P>
    (d) Consistent rewarding of each such event results in the gradual
    increase of synaptic strength, \(s\), which increases the
    probability of coincident firings and brings even more reward (the
    rich get richer).
  </P>

</div>
  


<DIV  CLASS="slide">
  <h1>associating an event with a place: learning in hippocampus place cells</h1>

  <img src="Bittner17-fig2ABC.png" class="figure-right" height=500>
    <img src="Bittner17-fig2F.png" class="figure-left" height=200>
    <P>
      Hippocampal
      <a href="https://en.wikipedia.org/wiki/Hippocampus_anatomy"
	 target=new>CA1</a> place fields can be produced in vivo <B>in a
	single trial</B> by potentiation of input that arrived seconds before and
      after
	 <a href="https://www.nature.com/articles/s41467-019-09767-w"
	 target=new>complex spike bursts</a> (F, left)... How???
    </P>
    <P>
      (A) Mouse on linear track (top), Gaussian functions representing
      place-field firing in the
      <a href="https://en.wikipedia.org/wiki/Hippocampus_anatomy"
	 target=new>CA3</a>
      neurons (green), the to-be-determined 
      plasticity rule that controls the synaptic weights of CA3 inputs
      (gray), Gaussian functions representing CA3 excitatory input
      weighted by above rule (black), and the resulting \(V_m\)
      [membrane potential] ramp in CA1
      neuron (blue). Red bar indicates plateau potential.
    </P>
    <P>
      (B) Activity of CA3 population versus time during induction
      trial.
    <P>
      (C) Synaptic weight values as a function of time from plateau
      (plasticity rule) inferred from the data (black) and standard [STDP] rule
      (red) for comparison. ampl., amplitude; a.u., arbitrary units.
    </P>
    <P>
      <small>
	  <I>Behavioral time scale synaptic plasticity underlies CA1
	    place fields</I>. Katie C. Bittner et al. Science 357,
	  1033–1036 (2017). 
      </small>
    </P>

</div>


<DIV  CLASS="slide">
  <h1>hippocampus place cell learning: "behavioral time-dependent plasticity"</h1>

  <img src="Bittner17-fig3D.png" class="figure-right" height=250>
  <P>
    Plot of postinduction
    <a href="https://en.wikipedia.org/wiki/Excitatory_postsynaptic_potential"
       target=new>EPSP</a> amplitude normalized to baseline versus the
       induction interval time for the entire population of
       neurons. Open gray symbols are individual neurons; black
       symbols are means. \(\tau_b\) (tau backward) from exponential
       fit of data ranging from 0 to –3250 ms (red line projecting to
       negative times). \(\tau_f\) (tau forward) from exponential fit
       of data ranging from 0 to +2000 ms (red line projecting to
    positive times).
  </P>
  <P class="incremental">
    "This time course allows inputs that were neither directly causal
    nor even temporally contiguous with postsynaptic activation
    (either APs or plateau potentials) to become potentiated, and the
    magnitude of this potentiation permits this to occur without
    substantial repetition. The time course also produces \(V_m\)
    depolarizations that have a PREDICTIVE quality, in that they peak
    and have a center of mass well before the actual induction [time
    and] location."
  </P>
  <P>
    <small>
      <I>Behavioral time scale synaptic plasticity underlies CA1
	place fields</I>. Katie C. Bittner et al. Science 357,
      1033–1036 (2017). 
    </small>
  </P>

</div>


<DIV  CLASS="slide">
  <h1>STDP and the Bienenstock-Cooper-Munro (BCM) rule</h1>

  <P>
    STDP can also be related to a nonlinear rate model where the
    weight change depends linearly on the presynaptic rate, but
    nonlinearly on the postsynaptic rate (Bienenstock et al.,
    1982). This can be achieved in two different ways.
  </P>
  <P>
    The first possibility (described on the next slide) is to allow only the 
    nearest-neighbor spikes to have a joint effect (instead of all-to-all
    spike coupling, as suggested above). This leads to
    a nonlinearity consistent with the BCM rule.
  </P>
  <P>
    For the second possibility, see the
    <a href="http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity"
       target=new>Scholarpedia article
      on STDP</a>.
  </P>

</div>



<DIV  CLASS="slide">
  <h1>more on STDP and the Bienenstock-Cooper-Munro (BCM) rule</h1>

  <img src="Izhikevich03-fig1.png" class="figure-right" height=500>
  <P>
    (A) The STDP curve.
  </P>
  <P>
    (B) Function controlling synaptic plasticity at the Cooper synapse
    receiving 20 Hz presynaptic stimulation.
  </P>
  <P>
    (C) All-to-all implementation of STDP: the net synaptic change is
    a combination of small changes induced by all possible pre- and
    postsynaptic pairs.
  </P>
  <P>
    (D) The result of application of STDP rule to
    <a href="http://en.wikipedia.org/wiki/Poisson_distribution"
       target=new>Poisson</a> spike
    trains.
  </P>
  <P>
    (E) The nearest-neighbor implementation of STDP. For each
    presynaptic spike, only one preceding andone succeeding
    postsynaptic spike are considered.
  </P>
  <P>
    (F) The resulting BCM function. Parameters are as in Figure 1A.
  </P>
  <P>
    <small>
      <I>Relating STDP to BCM</I>. Eugene M. Izhikevich and Niraj
      S. Desai. Neural Computation 15, 1511–1523 (2003).
    </small>
  </P>

</div>


    
<DIV  CLASS="slide">
  <h1>[EXTRA] STDP applied to handwritten digit recognition (W. Maass et al., 2009)</h1>

  <img src="Maas-STDP-fig1a.png" class="figure-right">
  <P>
  \(28\times 28\) pixel values \(x_j\) were encoded through population
  coding by binary variables \(y_i\). <small>
  Pixels were binarized to black/white. All pixels that were black in less
  than 5% of the training examples were removed, leaving \(m = 429\)
  external variables \(x_j\) that were encoded by \(n = 858\) spiking neurons
  \(y_i\). Spikes were produced for each variable \(y_i\) by a
  <a
  href="http://en.wikipedia.org/wiki/Poisson_distribution"
  target=new>Poisson</a> process with a rate of 40 Hz for \(y_i = 1\), and 0 Hz for \(y_i =
  0\),  at a simulation time step of \(1ms\). Every training example x was
  presented for \(50ms\). Every neuron \(y_i\) was connected to all \(K =
  10\) output neurons \(z_1, \ldots, z_{10}\). </small>
  A Poisson process caused firing of one of the neurons \(z_k\) on average
  every \(5ms\). 
  <P>
  The Winner-Take-All (WTA) mechanism ensured that only one of the output neurons could fire
  at any time step. The winning neuron at time step \(t\) was chosen by a
  <a href="https://en.wikipedia.org/wiki/Softmax_function" target=new>soft-max</a> step.
  <P>
  <font color=gray>
  [Specifically,
  $$
  p(z_k~\textrm{fires at time}~t\mid y) =
  \frac{e^{u_k\left(t\right)}}{\sum_{l=1}^{K} e^{u_l\left(t\right)}}
  $$
  where \(u_k(t) = \sum_{i=1}^n w_{ki}\tilde{y}_i(t) + w_{k0}\) represents
  the current membrane potential of neuron \(z_k\) (with \(\tilde{y}_i(t) =
  1\) if \(y_i\) fired within the time interval \([t-10ms,t]\), else
  \(\tilde{y}_i(t)=0\)).]
  </font>

</div>



<DIV  CLASS="slide">
  <h1>[EXTRA] STDP in digit recognition (cont.)</h1>

  <img src="Maas-STDP-fig1b.png" class="figure-right">
  <P>
    Learning curve for the two STDP rules that were used (with
    \(\sigma = 10ms\)). The synaptic weight \(w_{ki}\) is changed in
    dependence of the firing times \(t_{pre}\) of the presynaptic
    neuron \(y_i\) and \(t_{post}\) of the postsynaptic neuron
    \(z_k\). If \(z_k\) fires at time \(t\) without a firing of
    \(y_i\) in the interval \([t − \sigma, t + 2\sigma]\), \(w_{ki}\)
    is reduced by 1. The resulting weight change is in any case
    multiplied with the current learning rate \(\eta\),
    <font color=gray>which was chosen in the simulations according to the variance tracking
      rule.</font>
    <.P>

</div>



 <DIV  CLASS="slide">
  <h1>[EXTRA] STDP in digit recognition (cont.)</h1>

  <img src="Maas-STDP-fig2.png" class="figure-right">
  <P>
    Unsupervised classification learning and sparsification of firing of output
    neurons after training. For testing we presented three examples from an
    independent test set of handwritten digits 0, 3, 4 from the
    <a href="http://yann.lecun.com/exdb/mnist/" target=new>MNIST dataset</a>,
    and compared the firing of the output-neurons before and after
    learning.
  </P>
  <P>
    <B>(A)</B> Representation of the three handwritten digits 0, 3, 4 for
    \(50~ms\) each (\(150~ms\) total) by the 858 spiking neurons
    \(y_i\).
  </P>
  <P>
    <B>(B)</B> Responses of the 10 output neurons before training.
  </P>
  <P>
    <B>(C)</B> Responses of the 10 output neurons after STDP. The three output
    neurons \(z_4, z_9, z_6\) that respond have generated <B>internal 
      models</B> for the three shown handwritten digits according to the figure in
    the next slide.
  </P>

</div>



<DIV  CLASS="slide">
  <h1>[EXTRA] STDP in digit recognition (cont.)</h1>

  <img src="Maas-STDP-fig3bc.png" class="figure-right">
  <P>
    <B>(B)</B> The implicit internal models created by the neurons after 2000
    training examples are revealed by presenting their learned weights as input
    templates. Clearly, neurons created separate internal models 
    for different ways of writing the two digits 0 and 3.
  </P>
  <P>
    <B>(C)</B> Re-organized internal models after 2000 further training
    examples that included digit 4. Two output neurons had created internal
    models for the newly introduced digit 4.
  </P>
  <P class="incremental">
    When tested on sets of 10,000 new samples each, the network achieved a
    classification error of 2.19% on the digits 0 and 3 after 2000 training
    steps and 3.68% on all three digits after 4000 training steps.
  </P>

</div>

  
<div  CLASS="slide">
  <h1>summary: STDP and the discovery of the causal structure of the world</h1>
  
  <a
 href="https://en.wikipedia.org/wiki/Felix,_qui_potuit_rerum_cognoscere_causas"
 target=new><img src="felix-qui-potuit.jpg" class="figure-right"></a>
  <P>
    Modeling the world requires causal knowledge:
    <DIR><DIR>
	<a
	  href="http://en.wikipedia.org/wiki/Felix,_qui_potuit_rerum_cognoscere_causas"
	  target=new>Felix, qui potuit rerum cognoscere causas</a>
    </DIR></DIR>
  </P>
  <P>
    (recall <a href="wk-9-1.html#(4)"
	       target=n>Lecture 9.1</a>).
  </P>
  <P>
    STDP does that on the level of individual synapses, by
    distinguishing pre-before-post from post-before-pre situations
    (unlike rate-based rules, such as Hebb, which are correlational).
  </P>
  <P>
    Ultimately, one must determine which world events cause other
    events. Note that this undertaking — model-based reinforcement
    learning — must also be implemented with STDP and eligibility
    trace mechanisms, because that is all that the brain has at its
    disposal.
  </P>

</div>
  


<div class="footer">
<p>Last modified: Wed Apr 28 2021 at 20:51:07 EDT</p>
</div>
</body>
</html>
