<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<title>Psych 3140/6140 wk-13-2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<!-- <meta name="copyright" content="Copyright &169; 2008-2022 Shimon Edelman"/> -->
<meta name="font-size-adjustment" content="-1" /> <!-- DEFAULT SIZE -->
<link rel="stylesheet" href="../Slidy/w3c-blue3.css"
 type="text/css" media="screen, projection, print" />
 <link rel="stylesheet" href="extras.css"
 type="text/css" media="screen, projection, print" />
<script src="../Slidy/slidy.js" type="text/javascript">
</script>
<script type="text/javascript"
  src="../MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>

<!-- 
<rdf:RDF xmlns="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<License rdf:about="http://creativecommons.org/licenses/by-sa/2.5/">
<permits rdf:resource="http://creativecommons.org/ns#Reproduction"/>
<permits rdf:resource="http://creativecommons.org/ns#Distribution"/>
<requires rdf:resource="http://creativecommons.org/ns#Notice"/>
<requires rdf:resource="http://creativecommons.org/ns#Attribution"/>
<permits rdf:resource="http://creativecommons.org/ns#DerivativeWorks"/>
<requires rdf:resource="http://creativecommons.org/ns#ShareAlike"/>
</License>
</rdf:RDF>
-->

<!-- this defines the slide background -->

<div class="background">
  <div class="header">
  <!-- sized and colored via CSS -->
  </div>
  <!-- hidden style graphics to ensure they are saved with other content -->
  <img class="hidden" src="../Slidy/bullet.png" alt="" />
  <img class="hidden" src="../Slidy/fold.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold.bmp" alt="" />
  <img class="hidden" src="../Slidy/fold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/nofold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/unfold-dim.bmp" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-fold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-nofold-dim.gif" alt="" />
  <img class="hidden" src="../Slidy/bullet-unfold-dim.gif" alt="" />

  <div class="footer">
  <!-- modify the following text as appropriate -->
  Week 13.2 &#151;
  </div>
</div>

<!-- COVER PAGE SLIDE -->
<div class="slide cover">
  <div class="header">
    <h1>Psych 3140/6140</h1>
    <p><a href="http://shimon-edelman.github.io">Shimon Edelman</a>,
    &lt;<a href="mailto:se37@cornell.edu">se37@cornell.edu</a>&gt;</p>
  </div>
  <div style="float:left">
    <h2>Week 13: advanced topics I</h2>
    <h3>&nbsp;Lecture 13.2: real-world Bayes</h3>
  </div>
  <img src="../Lake-Michigan-horizon.jpg" title="Computing the Mind"
  class="figure-right"  height=70%>

</div>
<!-- END COVER PAGE -->



<div  CLASS="slide">
  <h1>real-world Bayes</h1>

  <img src="magic-realism.jpg" class="figure-right"
       title="Come on, honey, enough with the magic realism"
       height=400>
  <P>
    <B>Getting real about being Bayesian</B> (an algorithmic take):
  </P>
  <P>
    <I>Bayesian brains without probabilities</I>, A. N. Sanborn and
    N. Chater, Trends in Cognitive Sciences 20:883-893  (December 2016).
  </P>
  
</div>



<div  CLASS="slide">
  <h1>Bayesian Sampler vs. ideal Bayesian reasoning</h1>

  <img src="flounder-checkerboard.jpg" class="figure-right">
  <P>
    "Bayesian explanations have swept through cognitive science over the past
    two decades, from intuitive physics and causal learning, to perception,
    motor control and language. Yet people flounder with even the simplest
    probability questions. What explains this apparent paradox?"
  </P>
  <P class="incremental">
    "Bayesian brains need not represent or calculate probabilities at all and
    are, indeed, poorly adapted to do so. Instead, the brain is a
    <a href="https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/" target=new>Bayesian
      sampler</a>."
  </P>
  <P class="incremental">
    "The key insight:
    <BR>
      although explicitly representing a probability distribution is
      hard, drawing samples from it is relatively easy. Sampling does
      not require knowledge of the entire distribution. It can work
      merely with a LOCAL sense of RELATIVE
      PROBABILITIES. Intuitively, we have this local sense: once we
      ‘see’ a solution, it is often easy to see that it is better than
      another one, even if we cannot exactly say what either
      probability is. By continually sampling, we slowly build up a
      picture of <strike>all</strike> <I><B>most</B></I> of the
      possibilities. Using a number of samples much smaller than the
      number of hypotheses makes the computations feasible."
    </P>

</div>



<div  CLASS="slide">
  <h1>the android metaphor</h1>

  <img src="SanbornChater16-fig1A.png" class="figure-right" height=250>
  <P>
    "Sampling algorithms have difficulties with isolated modes and produce
    <a href="https://en.wikipedia.org/wiki/Autocorrelation"
    target=new>autocorrelations</a>.
  </P>
  <P>
    In this illustration, the android climbs the landscape of the (log)
    posterior probability distribution. The android uses the difference in
    height of its two feet to decide where to step, and its location is tracked
    over time (red <font color=red>x</font>). A histogram of its locations
    after many steps matches the mode of the probability distribution it
    explored."
  </P>
  
</div>


<div  CLASS="slide">
  <h1>comparing sampling methods on 2D distributions</h1>

  <img src="SanbornChater16-fig1B.png" class="figure-right" height=500>
  <P>
    "Each row is a different example probability distribution (two
    unimodal and two bimodal ones). The first column shows a
    topographic map of the posterior density. The second and third
    columns illustrate samples drawn using
    the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"
    target=new>Metropolis-Hastings</a> algorithm
    and <a href="https://en.wikipedia.org/wiki/Just_another_Gibbs_sampler"
	   target=new>JAGS</a> ("Just Another
    <a href="https://en.wikipedia.org/wiki/Gibbs_sampling"
       target=new>Gibbs Sampler</a>") program 
    respectively. Within each column are trace plots that show how the
    location of the sampler changes along each variable during each iteration
    of the sampling process.
  </P>
  <P>
    Autocorrelations are present when a sample depends on the value of
    the previous sample in the trace plots (e.g., Metropolis-Hastings
    in the second row). Also shown are bivariate scatterplots that can
    be used to compare the samples obtained against the true
    distributions in the first column. These show that not all of the
    modes are always sampled, even when thousands of samples are drawn
    (i.e., in the bottom row)."
  </P>
  
</div>




<div  CLASS="slide">
  <h1>Bayesian Sampler vs. ideal Bayesian reasoning</h1>

  <img src="SanbornChater16-tab1.png" class="figure-right" height=450>
  <P>
    "Bayesian cognitive models [using sampling instead of full-blown
    probability estimation] that operate well in complex domains
    actually predict probabilistic reasoning errors in simple
    domains."
  </P>
  <HR>
  <P>
    This is good news for the research program that attempts to
    explain reasoning and
    <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.584689/full"
    target=new><B>cognitive illusions</B></a> in terms of a Bayesian
    model.
  </P>
  
</div>



<div  CLASS="slide">
  <h1>why the CONJUNCTION FALLACY arises from a Bayesian sampler</h1>

  <img src="SanbornChater16-fig2A.png" class="figure-right" height=500>
  <P>
    "The top row illustrates a query about one piece of the puzzle.
    The bottom row illustrates that evaluating the probability of a
    conjunction is easier.
  </P>
  <P>
    <I>Top:</I> constituent question —<BR> What is the probability that
    the piece outlined in <font color=red>red</font> is in the correct
    position in the frame?
  </P>
  <P>
    <I>Bottom:</I> CONJUNCTION question —<BR> What is the probability that
    all of the pieces are in the correct positions in the frame?
  </P>
  <P class="incremental">
    <small>
      The correct locations of all the puzzle pieces cannot, of
      course, be more probable that the correct location of a single
      piece. Yet when considered in isolation, the evidence that an
      isolated piece is correct is weak (from a SAMPLING standpoint,
      it is not clear whether, e.g., swapping pieces leads to a higher
      or lower probability). But in the fully assembled puzzle (i.e.,
      the ‘peak’ in probability space), local comparisons are easy –
      switching any of the pieces would make the fit worse – so you
      can be nearly certain that all the pieces are in the correct
      position. So the whole puzzle will be judged more probable than
      a single piece, exhibiting the
      <a href="https://en.wikipedia.org/wiki/Conjunction_fallacy"
      target=new><B>conjunction fallacy</B></a>."
    </small>
  </P>
  
</div>


<div  CLASS="slide">
  <h1>why BASE-RATE NEGLECT arises from a Bayesian sampler</h1>

  <img src="SanbornChater16-fig2B.png" class="figure-right" height=400>
  <P>
    "Local assessments of relative probability are easy. Comparing the
    probability of seeing the two astronomical events in a year, or
    the probability of the two quotations appearing on a random
    website, are both relatively easy."
  </P>
  <P>
    "Comparing the probability of seeing one of the astronomical
    events in a year to the probability of seeing one of the
    quotations on a random website is more difficult. In particular,
    when
    comparing <a href="https://www.poetryfoundation.org/poems-and-poets/poems/detail/43290"
    target=new>"Things fall apart; the centre cannot hold"</a> to the
    eclipse, the quote may seem more likely as it is a common among
    quotes, yet this
    <a href="https://en.wikipedia.org/wiki/Base_rate_fallacy"
    target=new><B>neglects the base rates</B></a>: most websites do
    not have literary quotations, and there are many chances for an
    eclipse each year."
  </P>
  
</div>


<div  CLASS="slide">
  <h1>sampling and task richness</h1>

  <img src="all-white-puzzle.jpg" class="figure-right" height=400>
  <P>
    "If our brains do not respect the laws of probability for simple
    tasks, surely the Bayesian approach to the mind must fail in rich
    domains such as vision, language and motor control with huge data
    and hypothesis spaces.
  </P>
  <P>
    Viewing brains as sampling from complex probability distributions
    upends this argument. Rich, realistic tasks, in which there is a
    lot of contextual information available to guide sampling, are
    just those where the Bayesian sampler is most effective. <I>Rich
    tasks focus the sampler on the areas of the probability landscape
    that matter – those that arise through experience</I>. By limiting
    the region in which the sampler must search, rich problems can
    often be far easier for the sampler than apparently simpler, but
    more abstract, problems."
  </P>

</div>


<div  CLASS="slide">
  <h1>a "good enough" approach</h1>

  <img src="satisficing-1.png" class="figure-right" height=400>
  <P>
    "Moreover, the problem of learning the structure of the world, or
    interpreting an image or a sentence, involves
    finding <a href="https://en.wikipedia.org/wiki/Satisficing"
    target=new>‘good-enough’</a> hypotheses to usefully guide our
    actions, which can be achieved by local sampling in the
    probability landscape. Such hypotheses are no less valuable if an
    isolated peak, corresponding to an even better hypothesis,
    remained undiscovered."
  </P>
  <P class="incremental">
    ["Лучшее — враг хорошего"]
  </P>

</div>



<div  CLASS="slide">
  <h1>is local sampling good enough?</h1>

<!--   <img src="" class="figure-right" height=400> -->
  <P>
    "We suggest too that, for many real-world problems, multiple but
    distant peaks, corresponding to very different hypotheses about
    the world, may be rare, particularly when context and background
    knowledge are taken into account. Language is locally ambiguous,
    but it is very unlikely that the acoustic signal of a whole
    sentence in English happens to have an equally good interpretation
    in Latin [...]"
  </P>

</div>


<div  CLASS="slide">
  <h1>is local sampling good enough?</h1>

<!--   <img src="wk-14-1.html" class="figure-right" height=400> -->
  <P>
    "We suggest too that, for many real-world problems, multiple but
    distant peaks, corresponding to very different hypotheses about
    the world, may be rare, particularly when context and background
    knowledge are taken into account. Language is locally ambiguous,
    but it is very unlikely that the acoustic signal of a whole
    sentence in English happens to have an equally good interpretation
    in Latin [...]"
  </P>
  <P>
  Italian/Latin: I VITELLI DEI ROMANI SONO BELLI
  </P>
  <P>
  Latin meaning (Italian paraphrase): và, o Vitellio, al suono di guerra del dio Romano
  </P>
  <P>
  Latin meaning (English translation): go, Vitellus, to the sound of the Roman god of war
  </P>
  <P>
  Italian meaning (Latin paraphrase): ROMANORUM VITULI PULCHRI SUNT
  </P>
  <P>
  Italian meaning (English translation): the calves of the Romans are beautiful
  </P>
  <P class="incremental">
    <I>[This also illustrates how written words fails to capture the
  richness of natural language.]</I>
  </P>
  
</div>


<div  CLASS="slide">
  <h1>is local sampling good enough?</h1>

  <a href="http://www.ada.auckland.ac.nz/" target=new><img src="Ada.jpg" class="figure-right"></a>
  <P>
    "We suggest too that, for many real-world problems, multiple but
    distant peaks, corresponding to very different hypotheses about
    the world, may be rare, particularly when context and background
    knowledge are taken into account. Language is locally ambiguous,
    but it is very unlikely that the acoustic signal of a whole
    sentence in English happens to have an equally good interpretation
    in Latin [...]"
  <DIR><DIR>
    <I>
    Ce beau jardin fleurit en mai,<BR>
    Mais en hiver<BR>
    Jamais, jamais, jamais, jamais, jamais<BR>
	    N’est vert, n’est vert, n’est vert, n’est vert,
	    <a href="http://shakespeare.mit.edu/lear/lear.5.3.html"
	    target=new>n’est vert</a><BR> 
    </I>
  </DIR></DIR>
  <P>
  <HR>
  <P>
    [See <a
	   href="https://lans-tts.ua.ac.be/index.php/LANS-TTS/article/viewFile/141/83"
	   target=new>here</a> for a discussion of multilingual word-play in
    <a href="https://en.wikipedia.org/wiki/Vladimir_Nabokov" target=new>Nabokov</a>'s novel
    <a href="http://www.ada.auckland.ac.nz/" target=new><I>Ada, or
	Ardor</I></a>.]
  </P>
    
</div>


<div  CLASS="slide">
  <h1>is local sampling good enough?</h1>

  <a href="http://archive.thedali.org/mwebcgi/mweb.exe?request=record;id=123;type=101" target=new><img src="Dali-slave-market.gif"
  class="figure-right" title="a painting by S. Dalí" height=450></a>
  <P>
    <font color=gray>
      "We suggest too that, for many real-world problems, multiple but
      distant peaks, corresponding to very different hypotheses about
      the world, may be rare, particularly when context and background
      knowledge are taken into account. Language is locally ambiguous,
      but it is very unlikely that the acoustic signal of a whole
      sentence in English happens to have an equally good
      interpretation in Latin;</font> vision, too, is locally
      ambiguous but the probability that a portrait photograph could
    equally be reinterpreted as a rural scene is infinitesimal."
  </P>
  
</div>



<div  CLASS="slide">
  <h1>is local sampling good enough?</h1>

  <P>
    <font color=gray>
      "We suggest too that, for many real-world problems, multiple but
      distant peaks, corresponding to very different hypotheses about
      the world, may be rare, particularly when context and background
      knowledge are taken into account. Language is locally ambiguous,
      but it is very unlikely that the acoustic signal of a whole
      sentence in English happens to have an equally good
      interpretation in Latin; vision, too, is locally ambiguous but
      the probability that a portrait photograph could equally be
      reinterpreted as a rural scene is infinitesimal.</font>  In
      complex real-world problems, then, climbing a rugged probability
      landscape to find ‘good-enough’ hypothesis is crucial; linking
      to numerical probabilities, even approximately, is not. Thus,
      the view of cognition
      as <a href="https://en.wikipedia.org/wiki/Satisficing"
      target=new>satisficing</a> need not be viewed as opposed to the
      Bayesian approach. Rather, Bayesian sampling provides a
    mechanism for satisficing in real-world environments."
  </P>

</div>



<div  CLASS="slide">
  <h1>summing up: the Stones weigh in</h1>

  <img src="satisficing-2.jpg" class="figure-right" height=400>
  <P>
    <a href="https://www.youtube.com/watch?v=jv9sDn_2XkI" target=new>You can't</a> always get what you want<BR>
      You can't always get what you want<BR>
	You can't always get what you want<BR>
	  But if you try sometimes well you might find<BR>
	    You get what you need
	  </P>

</div>


<div class="footer">
<p>Last modified: Mon Apr 25 2022 at 16:21:58 EDT</p>
</div>
</body>
</html>
